{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Intro","text":""},{"location":"#official-python-package-for-supertonic","title":"Official Python Package for Supertonic","text":""},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install supertonic\n</code></pre>"},{"location":"#cli","title":"CLI","text":"<pre><code># Note: First run will download the model (~260MB) from HuggingFace\nsupertonic tts 'Supertonic is a lightning fast, on-device TTS system.' -o output.wav\n</code></pre>"},{"location":"#python","title":"Python","text":"<pre><code>from supertonic import TTS\n\n# Note: First run downloads model automatically (~260MB)\ntts = TTS(auto_download=True)\n\n# Get a voice style\nstyle = tts.get_voice_style(voice_name=\"M1\")\n\n# Generate speech\ntext = \"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\"\nwav, duration = tts.synthesize(text, voice_style=style)\n\n# Save to file\ntts.save_audio(wav, \"output.wav\")\n</code></pre> <p>Get Started with the Full Guide</p> <p>Explore installation options, voice customization, and advanced configuration.</p>"},{"location":"#requirements","title":"Requirements","text":"<p>Supertonic has minimal dependencies - just 4 core libraries:</p> <ul> <li>onnxruntime - Fast ONNX model inference</li> <li>numpy - Numerical operations</li> <li>soundfile - Audio file I/O</li> <li>huggingface-hub - Model downloads</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<p>\u26a1 Blazingly Fast: Generates speech up to 167\u00d7 faster than real-time on consumer hardware (M4 Pro)</p> <p>\ud83e\udeb6 Ultra Lightweight: Only 66M parameters, optimized for efficient on-device performance</p> <p>\ud83d\udcf1 On-Device Capable: Complete privacy and zero latency</p> <p>\ud83c\udfa8 Natural Text Handling: Seamlessly processes complex expressions without G2P module</p> <p>\u2699\ufe0f Highly Configurable: Adjust inference steps, speech speed, and other parameters</p> <p>\ud83e\udde9 Flexible Deployment: Deploy across servers, browsers, and edge devices</p>"},{"location":"#performance-benchmarks","title":"Performance Benchmarks","text":"Metrics: <ul> <li>Characters per Second: Measures throughput by dividing the number of input characters by the time required to generate audio. Higher is better.</li> <li>Real-time Factor (RTF): Measures the time taken to synthesize audio relative to its duration. Lower is better (e.g., RTF of 0.1 means it takes 0.1 seconds to generate one second of audio).</li> </ul>"},{"location":"#characters-per-second","title":"Characters per Second","text":"System Short (59 chars) Mid (152 chars) Long (266 chars) Supertonic (M4 pro - CPU) 912 1048 1263 Supertonic (M4 pro - WebGPU) 996 1801 2509 Supertonic (RTX4090) 2615 6548 12164 <code>API</code> ElevenLabs Flash v2.5 144 209 287 <code>API</code> OpenAI TTS-1 37 55 82 <code>API</code> Gemini 2.5 Flash TTS 12 18 24 <code>API</code> Supertone Sona speech 1 38 64 92 <code>Open</code> Kokoro 104 107 117 <code>Open</code> NeuTTS Air 37 42 47 <p>Notes: <code>API</code> = Cloud-based API services (measured from Seoul) <code>Open</code> = Open-source models Supertonic (M4 pro - CPU) and (M4 pro - WebGPU): Tested with ONNX Supertonic (RTX4090): Tested with PyTorch model Kokoro: Tested on M4 Pro CPU with ONNX NeuTTS Air: Tested on M4 Pro CPU with Q8-GGUF</p>"},{"location":"#real-time-factor","title":"Real-time Factor","text":"System Short (59 chars) Mid (152 chars) Long (266 chars) Supertonic (M4 pro - CPU) 0.015 0.013 0.012 Supertonic (M4 pro - WebGPU) 0.014 0.007 0.006 Supertonic (RTX4090) 0.005 0.002 0.001 <code>API</code> ElevenLabs Flash v2.5 0.133 0.077 0.057 <code>API</code> OpenAI TTS-1 0.471 0.302 0.201 <code>API</code> Gemini 2.5 Flash TTS 1.060 0.673 0.541 <code>API</code> Supertone Sona speech 1 0.372 0.206 0.163 <code>Open</code> Kokoro 0.144 0.124 0.126 <code>Open</code> NeuTTS Air 0.390 0.338 0.343 Additional Performance Data (5-step inference) <p>Characters per Second (5-step)</p> System Short (59 chars) Mid (152 chars) Long (266 chars) Supertonic (M4 pro - CPU) 596 691 850 Supertonic (M4 pro - WebGPU) 570 1118 1546 Supertonic (RTX4090) 1286 3757 6242 <p>Real-time Factor (5-step)</p> System Short (59 chars) Mid (152 chars) Long (266 chars) Supertonic (M4 pro - CPU) 0.023 0.019 0.018 Supertonic (M4 pro - WebGPU) 0.024 0.012 0.010 Supertonic (RTX4090) 0.011 0.004 0.002"},{"location":"#natural-text-handling","title":"Natural Text Handling","text":"<p>Supertonic is designed to handle complex, real-world text inputs that contain numbers, currency symbols, abbreviations, dates, and proper nouns.</p> <p>\ud83c\udfa7 View audio samples more easily: Check out our Interactive Demo for a better viewing experience of all audio examples</p> <p>Overview of Test Cases:</p> Category Key Challenges Supertonic ElevenLabs OpenAI Gemini Microsoft Financial Expression Decimal currency, abbreviated magnitudes (M, K), currency symbols, currency codes \u2705 \u274c \u274c \u274c \u274c Time and Date Time notation, abbreviated weekdays/months, date formats \u2705 \u274c \u274c \u274c \u274c Phone Number Area codes, hyphens, extensions (ext.) \u2705 \u274c \u274c \u274c \u274c Technical Unit Decimal numbers with units, abbreviated technical notations \u2705 \u274c \u274c \u274c \u274c Example 1: Financial Expression <p></p> \"The startup secured $5.2M in venture capital, a huge leap from their initial $450K seed round.\" <p></p> <p>Challenges:</p> <ul> <li>Decimal point in currency ($5.2M should be read as \"five point two million\")</li> <li>Abbreviated magnitude units (M for million, K for thousand)</li> <li>Currency symbol ($) that needs to be properly pronounced as \"dollars\"</li> </ul> <p>Audio Samples:</p> System Result Audio Supertonic \u2705 ElevenLabs Flash v2.5 \u274c OpenAI TTS-1 \u274c Gemini 2.5 Flash TTS \u274c VibeVoice Realtime 0.5B \u274c Example 2: Time and Date <p></p> \"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\" <p></p> <p>Challenges:</p> <ul> <li>Time expression with PM notation (4:45 PM)</li> <li>Abbreviated weekday (Wed)</li> <li>Abbreviated month (Apr)</li> <li>Full date format (Apr 3, 2024)</li> </ul> <p>Audio Samples:</p> System Result Audio Supertonic \u2705 ElevenLabs Flash v2.5 \u274c OpenAI TTS-1 \u274c Gemini 2.5 Flash TTS \u274c VibeVoice Realtime 0.5B \u274c Example 3: Phone Number <p></p> \"You can reach the hotel front desk at (212) 555-0142 ext. 402 anytime.\" <p></p> <p>Challenges:</p> <ul> <li>Area code in parentheses that should be read as separate digits</li> <li>Phone number with hyphen separator (555-0142)</li> <li>Abbreviated extension notation (ext.)</li> <li>Extension number (402)</li> </ul> <p>Audio Samples:</p> System Result Audio Supertonic \u2705 ElevenLabs Flash v2.5 \u274c OpenAI TTS-1 \u274c Gemini 2.5 Flash TTS \u274c VibeVoice Realtime 0.5B \u274c Example 4: Technical Unit <p></p> \"Our drone battery lasts 2.3h when flying at 30kph with full camera payload.\" <p></p> <p>Challenges:</p> <ul> <li>Decimal time duration with abbreviation (2.3h = two point three hours)</li> <li>Speed unit with abbreviation (30kph = thirty kilometers per hour)</li> <li>Technical abbreviations (h for hours, kph for kilometers per hour)</li> <li>Technical/engineering context requiring proper pronunciation</li> </ul> <p>Audio Samples:</p> System Result Audio Supertonic \u2705 ElevenLabs Flash v2.5 \u274c OpenAI TTS-1 \u274c Gemini 2.5 Flash TTS \u274c VibeVoice Realtime 0.5B \u274c <p>Note: These samples demonstrate how each system handles text normalization and pronunciation of complex expressions without requiring pre-processing or phonetic annotations.</p>"},{"location":"#citation","title":"Citation","text":"<p>The following papers describe the core technologies used in Supertonic. If you use this system in your research or find these techniques useful, please consider citing the relevant papers:</p>"},{"location":"#supertonictts-main-architecture","title":"SupertonicTTS: Main Architecture","text":"<p>This paper introduces the overall architecture of SupertonicTTS, including the speech autoencoder, flow-matching based text-to-latent module, and efficient design choices.</p> <pre><code>@article{kim2025supertonic,\n  title={SupertonicTTS: Towards Highly Efficient and Streamlined Text-to-Speech System},\n  author={Kim, Hyeongju and Yang, Jinhyeok and Yu, Yechan and Ji, Seunghun and Morton, Jacob and Bous, Frederik and Byun, Joon and Lee, Juheon},\n  journal={arXiv preprint arXiv:2503.23108},\n  year={2025},\n  url={https://arxiv.org/abs/2503.23108}\n}\n</code></pre>"},{"location":"#length-aware-rope-text-speech-alignment","title":"Length-Aware RoPE: Text-Speech Alignment","text":"<p>This paper presents Length-Aware Rotary Position Embedding (LARoPE), which improves text-speech alignment in cross-attention mechanisms.</p> <pre><code>@article{kim2025larope,\n  title={Length-Aware Rotary Position Embedding for Text-Speech Alignment},\n  author={Kim, Hyeongju and Lee, Juheon and Yang, Jinhyeok and Morton, Jacob},\n  journal={arXiv preprint arXiv:2509.11084},\n  year={2025},\n  url={https://arxiv.org/abs/2509.11084}\n}\n</code></pre>"},{"location":"#self-purifying-flow-matching-training-with-noisy-labels","title":"Self-Purifying Flow Matching: Training with Noisy Labels","text":"<p>This paper describes the self-purification technique for training flow matching models robustly with noisy or unreliable labels.</p> <pre><code>@article{kim2025spfm,\n  title={Training Flow Matching Models with Reliable Labels via Self-Purification},\n  author={Kim, Hyeongju and Yu, Yechan and Yi, June Young and Lee, Juheon},\n  journal={arXiv preprint arXiv:2509.19091},\n  year={2025},\n  url={https://arxiv.org/abs/2509.19091}\n}\n</code></pre>"},{"location":"#related-projects","title":"Related Projects","text":"<p>\ud83c\udfe0 Main Repository: github.com/supertone-inc/supertonic</p> <p>\ud83c\udfa7 Try it live: Hugging Face Spaces</p> <p>\ud83e\udd17 Model Repository: Hugging Face Models</p>"},{"location":"#license","title":"License","text":"<p>Code: MIT License</p> <p>Model: OpenRAIL-M License</p> <p>Copyright \u00a9 2025 Supertone Inc.</p>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quick-start","title":"Quick Start","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install supertonic\n</code></pre>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":"PythonCLI <pre><code>from supertonic import TTS\n\n# Note: First run downloads model automatically (~260MB)\ntts = TTS(auto_download=True)\n\n# Get a voice style\nstyle = tts.get_voice_style(voice_name=\"M1\")\n\n# Generate speech\ntext = \"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\"\nwav, duration = tts.synthesize(text, voice_style=style)\n# wav: np.ndarray, shape = (1, num_samples)\n# duration: np.ndarray, shape = (1,)\n\n# Save to file\ntts.save_audio(wav, \"output.wav\")\n</code></pre> Arguments for <code>tts.synthesize()</code> Parameter Description Default <code>text</code> Text to synthesize required <code>voice_style</code> Voice style object required <code>total_steps</code> Quality: 2-15 typical (higher=better) <code>5</code> <code>speed</code> Speed: 0.7 (slow) to 2.0 (fast) <code>1.05</code> <code>max_chunk_length</code> Max characters per chunk <code>300</code> <code>silence_duration</code> Silence between chunks (seconds) <code>0.3</code> <code>verbose</code> Show detailed progress <code>False</code> Shorthand <p>Use <code>tts(...)</code> as shorthand for <code>tts.synthesize(...)</code>: </p><pre><code>wav, duration = tts(\"This is a convenient shorthand method.\", voice_style=style)\n</code></pre><p></p> <pre><code># Note: First run downloads model automatically (~260MB)\nsupertonic tts 'Supertonic is a lightning fast, on-device TTS system.' -o output.wav\n</code></pre> CLI Options Option Description Default <code>-o</code>, <code>--output</code> Output file path required <code>--voice</code> Voice style: M1, F1, M2, F2, ... <code>M1</code> <code>--steps</code> Quality steps: 2-15 typical <code>5</code> <code>--speed</code> Speed multiplier: 0.7-2.0 <code>1.05</code> <code>--max-chunk-length</code> Characters per chunk <code>300</code> <code>--silence-duration</code> Silence between chunks (seconds) <code>0.3</code> <code>--custom-style-path</code> Path to custom voice style JSON - <code>-v</code>, <code>--verbose</code> Show detailed progress <code>False</code> Utility Commands <pre><code>supertonic list-voices   # List available voices\nsupertonic info          # Show model information\nsupertonic version       # Show version\n</code></pre>"},{"location":"quickstart/#try-in-colab","title":"Try in Colab","text":"<p>Run and experiment with Supertonic in Google Colab:</p> <p></p>"},{"location":"quickstart/#advanced-usage","title":"Advanced Usage","text":""},{"location":"quickstart/#voice-styles","title":"Voice Styles","text":"<p>Supertonic provides multiple built-in voice styles to choose from:</p> PythonCLI <pre><code>from supertonic import TTS\n\ntts = TTS()\n\n# List available voices\nvoice_list = tts.voice_style_names  # ex) ['M1', 'M2', 'F1', 'F2']\n\n# Try different voices\nfor voice_name in voice_list:\n    style = tts.get_voice_style(voice_name)\n    wav, dur = tts.synthesize(f\"This is the {voice_name} voice style demonstration.\", voice_style=style)\n    tts.save_audio(wav, f\"output_{voice_name}.wav\")\n</code></pre> <pre><code># List available voices\nsupertonic list-voices\n\n# Try different voices\nsupertonic tts 'This is the M1 voice style demonstration.' --voice M1 -o output_m1.wav\nsupertonic tts 'This is the M2 voice style demonstration.' --voice M2 -o output_m2.wav\nsupertonic tts 'This is the F1 voice style demonstration.' --voice F1 -o output_f1.wav\nsupertonic tts 'This is the F2 voice style demonstration.' --voice F2 -o output_f2.wav\n</code></pre>"},{"location":"quickstart/#custom-voice-styles","title":"Custom Voice Styles","text":"<p>Load custom voice styles from JSON:</p> PythonCLI <pre><code>from supertonic import TTS\nfrom pathlib import Path\n\ntts = TTS()\n\n# Load custom style from JSON\ncustom_style = tts.get_voice_style_from_path(Path(\"custom_voice.json\"))\nwav, dur = tts.synthesize(\"Using a custom voice style from JSON file.\", voice_style=custom_style)\n</code></pre> <pre><code>supertonic tts 'Using a custom voice style from JSON file.' --custom-style-path custom_voice.json -o output_custom.wav\n</code></pre>"},{"location":"quickstart/#speech-speed-control","title":"Speech Speed Control","text":"<p>Adjust speech rate from 0.7\u00d7 (slow) to 2.0\u00d7 (fast):</p> Speed Description <code>0.7</code> Slow pace <code>1.0</code> Normal pace <code>1.3</code> Faster pace <code>2.0</code> Fast pace PythonCLI <pre><code>from supertonic import TTS\n\ntts = TTS()\nstyle = tts.get_voice_style(\"F1\")\n\ntexts = {\n    0.7: \"This is slow speed demonstration.\",\n    1.0: \"This is normal speed demonstration.\",\n    1.3: \"This is fast speed demonstration.\",\n    2.0: \"This is fastest speed demonstration.\",\n}\n\nfor speed, text in texts.items():\n    wav, dur = tts.synthesize(text, voice_style=style, speed=speed)\n    tts.save_audio(wav, f\"output_{speed:.1f}_speed.wav\")\n</code></pre> <pre><code>supertonic tts 'This is slow speed demonstration.' --voice F1 --speed 0.7 -o output_0.7_speed.wav\nsupertonic tts 'This is normal speed demonstration.' --voice F1 --speed 1.0 -o output_1.0_speed.wav\nsupertonic tts 'This is fast speed demonstration.' --voice F1 --speed 1.3 -o output_1.3_speed.wav\nsupertonic tts 'This is fastest speed demonstration.' --voice F1 --speed 2.0 -o output_2.0_speed.wav\n</code></pre>"},{"location":"quickstart/#speech-quality-control","title":"Speech Quality Control","text":"<p>Adjust synthesis quality with <code>total_steps</code> parameter:</p> Steps Quality Synthesis Speed <code>2</code> Low Fast <code>5</code> Balanced Normal <code>10</code> High Slow PythonCLI <pre><code>from supertonic import TTS\n\ntts = TTS()\nstyle = tts.get_voice_style(\"M1\")\n\ntexts = {\n    2: \"This is low steps demonstration.\",\n    5: \"This is balanced steps demonstration.\",\n    10: \"This is high steps demonstration.\",\n}\n\nfor steps, text in texts.items():\n    wav, dur = tts.synthesize(text, voice_style=style, total_steps=steps)\n    tts.save_audio(wav, f\"output_{steps:02d}_steps.wav\")\n</code></pre> <pre><code>supertonic tts 'This is low steps demonstration.' --steps 2 -o output_02_steps.wav\nsupertonic tts 'This is balanced steps demonstration.' --steps 5 -o output_05_steps.wav\nsupertonic tts 'This is high steps demonstration.' --steps 10 -o output_10_steps.wav\n</code></pre>"},{"location":"quickstart/#long-text-handling","title":"Long Text Handling","text":"<p>Supertonic automatically chunks long texts for optimal processing:</p> Parameter Description Default <code>max_chunk_length</code> Maximum characters per chunk <code>300</code> <code>silence_duration</code> Silence between chunks (seconds) <code>0.3</code> PythonCLI <pre><code>from supertonic import TTS\n\ntts = TTS()\nstyle = tts.get_voice_style(\"F1\")\n\nlong_text = \"\"\"\nArtificial intelligence has transformed many fields.\nFrom healthcare to transportation, AI systems are making impacts.\nNatural language processing allows computers to understand human language.\nThese advances are opening up new possibilities.\n\"\"\"\n\nwav, dur = tts.synthesize(\n    long_text,\n    voice_style=style,\n    max_chunk_length=300,\n    silence_duration=0.3\n)\ntts.save_audio(wav, \"output.wav\")\n</code></pre> <pre><code>TEXT=\"Artificial intelligence has transformed many fields. From healthcare to transportation, AI systems are making impacts. Natural language processing allows computers to understand human language. These advances are opening up new possibilities.\"\n\nsupertonic tts \"$TEXT\" --max-chunk-length 150 --silence-duration 0.3 --voice F1 -o output.wav  # Note: Use double quotes for shell variables\n</code></pre> <p>Auto-chunking</p> <p>Text chunking is enabled by default. Supertonic splits by paragraphs and respects sentence boundaries, handling abbreviations like Mr., Dr., Ph.D. correctly.</p>"},{"location":"quickstart/#text-validation","title":"Text Validation","text":"<p>Check if your text can be processed before synthesis:</p> PythonCLI <pre><code>from supertonic import TTS\n\ntts = TTS()\ntext_processor = tts.model.text_processor\n\n# Check if text is supported\ntext = \"Hello World! Welcome to \u200b\u4e16\u754c\u200b.\"\nis_valid, unsupported = text_processor.validate_text(text)\n\nif not is_valid:\n    print(f\"Unsupported characters: {unsupported}\")\n    # Will show: ['\u200b\u4e16\u200b', '\u200b\u754c\u200b'] (or similar)\n\n# Get all supported characters\nsupported_chars = text_processor.supported_character_set\nprint(f\"Supported characters: {sorted(list(supported_chars))}\")\n</code></pre> <pre><code># This will output an error because the text contains unsupported characters\nsupertonic tts 'Hello World! Welcome to \u200b\u4e16\u754c\u200b.' -o output.wav\n</code></pre>"},{"location":"quickstart/#performance-tuning","title":"Performance Tuning","text":""},{"location":"quickstart/#thread-configuration","title":"Thread Configuration","text":"<p>By default, ONNX Runtime automatically detects and uses optimal thread counts for your system. For advanced use cases, you can manually configure threads:</p> Parameter Description <code>intra_op_num_threads</code> Threads for parallelism within each operation <code>inter_op_num_threads</code> Threads for parallelism between operations PythonCLI <pre><code>from supertonic import TTS\n\n# Auto-detect (recommended)\ntts = TTS()\n\n# High-performance server\ntts = TTS(intra_op_num_threads=12, inter_op_num_threads=12)\n\n# Low-resource environment\ntts = TTS(intra_op_num_threads=2, inter_op_num_threads=2)\n</code></pre> <pre><code># Set thread counts via environment variables\nexport SUPERTONIC_INTRA_OP_THREADS=12\nexport SUPERTONIC_INTER_OP_THREADS=12\n\nsupertonic tts 'This is the thread configuration demonstration.' -o output.wav --voice M1\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference \u2014 Complete API documentation</li> <li>CLI Reference \u2014 Full command-line interface guide</li> </ul>"},{"location":"voices/","title":"Voices","text":""},{"location":"voices/#voices","title":"Voices","text":"<p>Supertonic offers a diverse selection of 10 pre-built voices\u20145 male and 5 female\u2014each designed for specific use cases and tonal qualities.</p>"},{"location":"voices/#available-voices","title":"Available Voices","text":""},{"location":"voices/#male-voices","title":"Male Voices","text":"Voice Description Use Cases Example M1 Lively, upbeat male voice with confident energy and a standard, clear tone. Promotional videos, upbeat explainers, general-purpose narration, casual announcements. M2 Deep, robust male voice; calm, composed, and serious with a grounded presence. Corporate content, serious announcements, documentaries, formal guidance. M3 Polished, authoritative male voice; confident and trustworthy with strong presentation quality. Business presentations, leadership messages, investor briefings, high-trust narration. M4 Soft, neutral-toned male voice; gentle and approachable with a youthful, friendly quality. Educational content, friendly explainers, onboarding guides, youth-oriented narration. M5 Warm, soft-spoken male voice; calm and soothing with a natural storytelling quality. Audiobooks, relaxation content, bedtime stories, reflective or emotional narration."},{"location":"voices/#female-voices","title":"Female Voices","text":"Voice Description Use Cases Example F1 Calm female voice with a slightly low tone; steady and composed. Customer service, guided instructions, meditative content, professional narration. F2 Bright, cheerful female voice; lively, playful, and youthful with spirited energy. Youth content, playful ads, social media videos, character voices. F3 Clear, professional announcer-style female voice; articulate and broadcast-ready. Commercials, documentaries, news-style narration, formal presentations. F4 Crisp, confident female voice; distinct and expressive with strong delivery. Business explainers, training videos, pitch decks, product announcements. F5 Kind, gentle female voice; soft-spoken, calm, and naturally soothing. Audiobooks, supportive messages, wellness content, empathetic narration."},{"location":"voices/#custom-voices","title":"Custom Voices","text":"<p>Coming Soon</p> <p>Custom voice service is currently in development.</p> <p>Subscribe to our newsletter to receive updates on Custom Voices availability and other new features.</p> <p>For enterprise or business inquiries, reach out to contact@supertone.ai.</p>"},{"location":"api/","title":"Overview","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<pre><code>from supertonic import TTS\n\ntts = TTS(auto_download=True)       # Initialize TTS engine\n\nstyle = tts.get_voice_style(voice_name=\"M1\")   # Get a voice style: M1, M2, F1, F2\n\nwav, duration = tts.synthesize(\n    text=\"Your text here.\",         # Text to synthesize\n    voice_style=style,              # Voice style object\n    total_steps=5,                  # Quality: 2 (low quality) to 15 (high quality)\n    speed=1.05,                     # Speed: 0.7 (slow) to 2.0 (fast)\n    max_chunk_length=300,           # Max characters per chunk\n    silence_duration=0.3,           # Silence between chunks (seconds)\n    verbose=False                   # Show detailed progress (default: False)\n)\n</code></pre>"},{"location":"api/#modules","title":"Modules","text":"<ul> <li>pipeline - High-level TTS interface with automatic model loading and voice style management</li> <li>core - Core TTS engine classes and data structures</li> <li>loader - Functions for loading models and voice styles</li> <li>utils - Helper functions for text processing and audio utilities</li> <li>config - Configuration constants and default values</li> <li>cli - Command-line interface implementation</li> </ul>"},{"location":"api/cli/","title":"cli","text":""},{"location":"api/cli/#supertoniccli","title":"supertonic.cli","text":""},{"location":"api/cli/#supertonic.cli","title":"supertonic.cli","text":"<p>Command-line interface for Supertonic TTS.</p> <p>This module provides a command-line interface for easy text-to-speech synthesis, batch processing, and model management.</p> <p>Functions:</p> Name Description <code>cmd_say</code> <p>Generate speech and play it directly without saving a file.</p> <code>cmd_tts</code> <p>Generate speech from text using TTS.</p> <code>cmd_list_voices</code> <p>List available voice styles.</p> <code>cmd_info</code> <p>Show model information.</p> <code>cmd_download</code> <p>Download model from HuggingFace.</p> <code>cmd_version</code> <p>Show version information.</p> <code>create_parser</code> <p>Create and return the CLI argument parser.</p> <code>main</code> <p>Main CLI entry point.</p> <p>Attributes:</p> Name Type Description <code>logger</code>"},{"location":"api/cli/#supertonic.cli.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_say","title":"cmd_say","text":"<pre><code>cmd_say(args)\n</code></pre> <p>Generate speech and play it directly without saving a file.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_say(args):\n    \"\"\"Generate speech and play it directly without saving a file.\"\"\"\n    # Setup logging based on verbose flag\n    if args.verbose:\n        logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n    else:\n        logging.basicConfig(level=logging.WARNING, format=\"%(levelname)s: %(message)s\")\n\n    # Check if sounddevice is installed\n    try:\n        import sounddevice as sd\n    except ImportError:\n        print(\"\u274c Error: sounddevice is required for the 'say' command.\")\n        print(\"   Install it with: pip install supertonic[playback]\")\n        print(\"   Or: pip install sounddevice\")\n        sys.exit(1)\n\n    if args.verbose:\n        print(f\"\ud83c\udfa4 Generating speech: {args.text[:50]}...\")\n\n    try:\n        # Initialize TTS\n        print(\"Loading model...\")\n        load_start = time.time()\n        tts = TTS()\n        load_time = time.time() - load_start\n        print(f\"   -&gt; Model loaded in {load_time:.2f}s\")\n\n        # Text processing\n        if args.verbose:\n            print(\"Processing text...\")\n            text_start = time.time()\n\n            # Show text validation\n            is_valid, unsupported = tts.model.text_processor.validate_text(args.text)\n            # Show preprocessed text\n            preprocessed = tts.model.text_processor._preprocess_text(args.text)\n\n            text_time = time.time() - text_start\n            print(f\"   -&gt; Text processed in {text_time:.3f}s\")\n\n            print(f\"   Original: {args.text[:80]}{'...' if len(args.text) &gt; 80 else ''}\")\n            if not is_valid:\n                print(f\"   \u26a0\ufe0f  Unsupported chars: {unsupported[:10]}\")\n            if preprocessed != args.text:\n                print(\n                    f\"   Preprocessed: {preprocessed[:80]}{'...' if len(preprocessed) &gt; 80 else ''}\"\n                )\n\n        # Get voice style\n        print(f\"Loading voice style ({args.custom_style_path or args.voice})...\")\n        style_start = time.time()\n        if args.custom_style_path:\n            voice_style = tts.get_voice_style_from_path(args.custom_style_path)\n        else:\n            voice_style = tts.get_voice_style(args.voice)\n        style_time = time.time() - style_start\n        print(f\"   -&gt; Voice style loaded in {style_time:.3f}s\")\n\n        # Generate speech\n        print(\"Generating speech...\")\n        start_time = time.time()\n        wav, duration = tts.synthesize(\n            args.text,\n            voice_style=voice_style,\n            total_steps=args.steps,\n            speed=args.speed,\n            max_chunk_length=args.max_chunk_length,\n            silence_duration=args.silence_duration,\n            verbose=args.verbose,\n        )\n        elapsed_time = time.time() - start_time\n        print(f\"   -&gt; Speech generated in {elapsed_time:.2f}s\")\n\n        # Play audio directly\n        print(f\"Playing {duration[0]:.2f}s audio...\")\n        sd.play(wav.squeeze(), tts.sample_rate)\n        sd.wait()  # Wait until audio is finished playing\n        print(\"   -&gt; Audio played\")\n\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        if args.verbose:\n            logger.exception(\"TTS playback failed with exception:\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_tts","title":"cmd_tts","text":"<pre><code>cmd_tts(args)\n</code></pre> <p>Generate speech from text using TTS.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_tts(args):\n    \"\"\"Generate speech from text using TTS.\"\"\"\n    # Setup logging based on verbose flag\n    if args.verbose:\n        logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n    else:\n        logging.basicConfig(level=logging.WARNING, format=\"%(levelname)s: %(message)s\")\n\n    if args.verbose:\n        print(f\"\ud83c\udfa4 Generating speech: {args.text[:50]}...\")\n\n    try:\n        # Initialize TTS\n        print(\"Loading model...\")\n        load_start = time.time()\n        tts = TTS()\n        load_time = time.time() - load_start\n        print(f\"   -&gt; Model loaded in {load_time:.2f}s\")\n\n        # Text processing\n        if args.verbose:\n            print(\"Processing text...\")\n            text_start = time.time()\n\n            # Show text validation\n            is_valid, unsupported = tts.model.text_processor.validate_text(args.text)\n            # Show preprocessed text\n            preprocessed = tts.model.text_processor._preprocess_text(args.text)\n\n            text_time = time.time() - text_start\n            print(f\"   -&gt; Text processed in {text_time:.3f}s\")\n\n            print(f\"   Original: {args.text[:80]}{'...' if len(args.text) &gt; 80 else ''}\")\n            if not is_valid:\n                print(f\"   \u26a0\ufe0f  Unsupported chars: {unsupported[:10]}\")\n            if preprocessed != args.text:\n                print(\n                    f\"   Preprocessed: {preprocessed[:80]}{'...' if len(preprocessed) &gt; 80 else ''}\"\n                )\n\n        # Get voice style\n        print(f\"Loading voice style ({args.custom_style_path or args.voice})...\")\n        style_start = time.time()\n        if args.custom_style_path:\n            voice_style = tts.get_voice_style_from_path(args.custom_style_path)\n        else:\n            voice_style = tts.get_voice_style(args.voice)\n        style_time = time.time() - style_start\n        print(f\"   -&gt; Voice style loaded in {style_time:.3f}s\")\n\n        # Generate speech\n        print(\"Generating speech...\")\n        start_time = time.time()\n        wav, duration = tts.synthesize(\n            args.text,\n            voice_style=voice_style,\n            total_steps=args.steps,\n            speed=args.speed,\n            max_chunk_length=args.max_chunk_length,\n            silence_duration=args.silence_duration,\n            verbose=args.verbose,\n        )\n        elapsed_time = time.time() - start_time\n        print(f\"   -&gt; Speech generated in {elapsed_time:.2f}s\")\n\n        # Save audio\n        print(f\"Saving {duration[0]:.2f}s audio to {args.output}...\")\n        tts.save_audio(wav, args.output)\n        print(f\"   -&gt; Audio saved to {args.output}\")\n\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        if args.verbose:\n            logger.exception(\"TTS generation failed with exception:\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_list_voices","title":"cmd_list_voices","text":"<pre><code>cmd_list_voices(args)\n</code></pre> <p>List available voice styles.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_list_voices(args):\n    \"\"\"List available voice styles.\"\"\"\n    try:\n        tts = TTS()\n        styles = tts.voice_style_names\n\n        print(f\"\ud83d\udce2 Available voice styles ({len(styles)}):\\n\")\n        for style in styles:\n            print(f\"  \u2022 {style}\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_info","title":"cmd_info","text":"<pre><code>cmd_info(args)\n</code></pre> <p>Show model information.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_info(args):\n    \"\"\"Show model information.\"\"\"\n    try:\n        tts = TTS()\n\n        print(\"\u2139\ufe0f  Supertonic Model Information\\n\")\n        print(f\"Model directory: {tts.model_dir}\")\n        print(f\"Sample rate: {tts.sample_rate} Hz\")\n        print(f\"\\nAvailable voice styles: {', '.join(tts.voice_style_names)}\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_download","title":"cmd_download","text":"<pre><code>cmd_download(args)\n</code></pre> <p>Download model from HuggingFace.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_download(args):\n    \"\"\"Download model from HuggingFace.\"\"\"\n    from .loader import download_model, get_cache_dir\n\n    print(\"\ud83d\udce5 Downloading Supertonic model...\")\n\n    try:\n        cache_dir = get_cache_dir()\n        download_model(cache_dir)\n        print(f\"\u2705 Model downloaded to: {cache_dir}\")\n    except Exception as e:\n        print(f\"\u274c Download failed: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#supertonic.cli.cmd_version","title":"cmd_version","text":"<pre><code>cmd_version(args)\n</code></pre> <p>Show version information.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def cmd_version(args):\n    \"\"\"Show version information.\"\"\"\n    print(f\"supertonic {__version__}\")\n</code></pre>"},{"location":"api/cli/#supertonic.cli.create_parser","title":"create_parser","text":"<pre><code>create_parser() -&gt; ArgumentParser\n</code></pre> <p>Create and return the CLI argument parser.</p> <p>This function is separated to allow documentation generation tools to extract CLI arguments automatically.</p> <p>Returns:</p> Type Description <code>ArgumentParser</code> <p>ArgumentParser configured with all Supertonic CLI commands</p> Source code in <code>supertonic/cli.py</code> <pre><code>def create_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Create and return the CLI argument parser.\n\n    This function is separated to allow documentation generation tools\n    to extract CLI arguments automatically.\n\n    Returns:\n        ArgumentParser configured with all Supertonic CLI commands\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"supertonic\",\n        description=\"Supertonic - High-quality Text-to-Speech synthesis\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  # Generate and play speech directly (no file saved)\n  supertonic say 'Hello, welcome to the world!'\n\n  # Generate speech from text and save to file\n  supertonic tts 'Hello, welcome to the world!' -o output.wav\n\n  # Use different voice and quality\n  supertonic say 'This is a female voice style.' --voice F1 --steps 10\n  supertonic tts 'This is a female voice style.' -o hello.wav --voice F1 --steps 10\n\n  # Use custom voice style from JSON file\n  supertonic say 'This is a custom voice test.' --custom-style-path ./my_voice.json\n\n  # Long text with custom chunking\n  supertonic tts 'This is a very long text.' -o output.wav --max-chunk-length 200\n\n  # List available voices\n  supertonic list-voices\n        \"\"\",\n    )\n\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n\n    # Common arguments helper function\n    def add_common_args(p):\n        p.add_argument(\n            \"-v\",\n            \"--verbose\",\n            action=\"store_true\",\n            help=\"Enable verbose output with detailed logging\",\n        )\n\n    # Say command (play audio directly without saving)\n    parser_say = subparsers.add_parser(\n        \"say\", help=\"Generate speech and play it directly without saving a file\"\n    )\n    parser_say.add_argument(\"text\", help=\"Text to synthesize and play\")\n    parser_say.add_argument(\"--voice\", default=\"M1\", help=\"Voice style (default: M1)\")\n    parser_say.add_argument(\n        \"--custom-style-path\",\n        type=str,\n        default=None,\n        help=\"Path to custom voice style JSON file (overrides --voice if provided)\",\n    )\n    parser_say.add_argument(\n        \"--steps\", type=int, default=5, help=\"Quality steps (default: 5, higher=better)\"\n    )\n    parser_say.add_argument(\n        \"--speed\",\n        type=float,\n        default=1.05,\n        help=\"Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)\",\n    )\n    parser_say.add_argument(\n        \"--max-chunk-length\",\n        type=int,\n        default=300,\n        help=\"Maximum characters per chunk (default: 300)\",\n    )\n    parser_say.add_argument(\n        \"--silence-duration\",\n        type=float,\n        default=0.3,\n        help=\"Silence between chunks in seconds (default: 0.3)\",\n    )\n    add_common_args(parser_say)\n    parser_say.set_defaults(func=cmd_say)\n\n    # TTS command\n    parser_tts = subparsers.add_parser(\"tts\", aliases=[\"t\"], help=\"Generate speech from text\")\n    parser_tts.add_argument(\"text\", help=\"Text to synthesize\")\n    parser_tts.add_argument(\"-o\", \"--output\", required=True, help=\"Output WAV file\")\n    parser_tts.add_argument(\"--voice\", default=\"M1\", help=\"Voice style (default: M1)\")\n    parser_tts.add_argument(\n        \"--custom-style-path\",\n        type=str,\n        default=None,\n        help=\"Path to custom voice style JSON file (overrides --voice if provided)\",\n    )\n    parser_tts.add_argument(\n        \"--steps\", type=int, default=5, help=\"Quality steps (default: 5, higher=better)\"\n    )\n    parser_tts.add_argument(\n        \"--speed\",\n        type=float,\n        default=1.05,\n        help=\"Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)\",\n    )\n    parser_tts.add_argument(\n        \"--max-chunk-length\",\n        type=int,\n        default=300,\n        help=\"Maximum characters per chunk (default: 300)\",\n    )\n    parser_tts.add_argument(\n        \"--silence-duration\",\n        type=float,\n        default=0.3,\n        help=\"Silence between chunks in seconds (default: 0.3)\",\n    )\n    add_common_args(parser_tts)\n    parser_tts.set_defaults(func=cmd_tts)\n\n    # Backward compatibility: synthesize command (deprecated)\n    parser_synth = subparsers.add_parser(\n        \"synthesize\", aliases=[\"s\"], help=\"(Deprecated: use tts) Generate speech from text\"\n    )\n    parser_synth.add_argument(\"text\", help=\"Text to synthesize\")\n    parser_synth.add_argument(\"-o\", \"--output\", required=True, help=\"Output WAV file\")\n    parser_synth.add_argument(\"--voice\", default=\"M1\", help=\"Voice style (default: M1)\")\n    parser_synth.add_argument(\n        \"--steps\", type=int, default=5, help=\"Quality steps (default: 5, higher=better)\"\n    )\n    add_common_args(parser_synth)\n    parser_synth.set_defaults(func=cmd_tts)\n\n    # List voices command\n    parser_voices = subparsers.add_parser(\n        \"list-voices\", aliases=[\"lv\"], help=\"List available voice styles\"\n    )\n    parser_voices.set_defaults(func=cmd_list_voices)\n\n    # Info command\n    parser_info = subparsers.add_parser(\"info\", aliases=[\"i\"], help=\"Show model information\")\n    parser_info.set_defaults(func=cmd_info)\n\n    # Download command\n    parser_download = subparsers.add_parser(\n        \"download\", aliases=[\"d\"], help=\"Download model from HuggingFace\"\n    )\n    parser_download.set_defaults(func=cmd_download)\n\n    # Version command\n    parser_version = subparsers.add_parser(\n        \"version\", aliases=[\"v\"], help=\"Show version information\"\n    )\n    parser_version.set_defaults(func=cmd_version)\n\n    return parser\n</code></pre>"},{"location":"api/cli/#supertonic.cli.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main CLI entry point.</p> Source code in <code>supertonic/cli.py</code> <pre><code>def main():\n    \"\"\"Main CLI entry point.\"\"\"\n    parser = create_parser()\n\n    # Parse args\n    args = parser.parse_args()\n\n    if not args.command:\n        parser.print_help()\n        sys.exit(1)\n\n    # Execute command\n    try:\n        args.func(args)\n    except KeyboardInterrupt:\n        print(\"\\n\u26a0\ufe0f  Interrupted by user\")\n        sys.exit(130)\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/config/","title":"config","text":""},{"location":"api/config/#supertonicconfig","title":"supertonic.config","text":""},{"location":"api/config/#supertonic.config","title":"supertonic.config","text":"<p>Configuration and constants for Supertonic TTS package.</p> <p>This module centralizes all configuration values, magic numbers, and default settings used throughout the package.</p> <p>Attributes:</p> Name Type Description <code>logger</code> <code>DEFAULT_MODEL_REPO</code> <code>DEFAULT_CACHE_DIR</code> <code>DEFAULT_MODEL_REVISION</code> <code>ONNX_DIR</code> <code>VOICE_STYLES_DIR</code> <code>CFG_REL_PATH</code> <code>UNICODE_INDEXER_REL_PATH</code> <code>DP_ONNX_REL_PATH</code> <code>TEXT_ENC_ONNX_REL_PATH</code> <code>VECTOR_EST_ONNX_REL_PATH</code> <code>VOCODER_ONNX_REL_PATH</code> <code>DEFAULT_TOTAL_STEPS</code> <code>DEFAULT_SPEED</code> <code>DEFAULT_MAX_CHUNK_LENGTH</code> <code>DEFAULT_SILENCE_DURATION</code> <code>MIN_SPEED</code> <code>MAX_SPEED</code> <code>MIN_TOTAL_STEPS</code> <code>MAX_TOTAL_STEPS</code> <code>DEFAULT_ONNX_PROVIDERS</code> <code>DEFAULT_INTRA_OP_NUM_THREADS</code> <code>DEFAULT_INTER_OP_NUM_THREADS</code> <code>MAX_TEXT_LENGTH</code> <code>LOG_FORMAT</code> <code>LOG_LEVEL</code>"},{"location":"api/config/#supertonic.config.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_MODEL_REPO","title":"DEFAULT_MODEL_REPO  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MODEL_REPO = getenv(\n    \"SUPERTONIC_MODEL_REPO\", \"Supertone/supertonic\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_CACHE_DIR","title":"DEFAULT_CACHE_DIR  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CACHE_DIR = getenv(\n    \"SUPERTONIC_CACHE_DIR\",\n    str(home() / \".cache\" / \"supertonic\"),\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_MODEL_REVISION","title":"DEFAULT_MODEL_REVISION  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MODEL_REVISION = getenv(\n    \"SUPERTONIC_MODEL_REVISION\", \"v1.0.0\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.ONNX_DIR","title":"ONNX_DIR  <code>module-attribute</code>","text":"<pre><code>ONNX_DIR = Path('onnx')\n</code></pre>"},{"location":"api/config/#supertonic.config.VOICE_STYLES_DIR","title":"VOICE_STYLES_DIR  <code>module-attribute</code>","text":"<pre><code>VOICE_STYLES_DIR = Path('voice_styles')\n</code></pre>"},{"location":"api/config/#supertonic.config.CFG_REL_PATH","title":"CFG_REL_PATH  <code>module-attribute</code>","text":"<pre><code>CFG_REL_PATH = ONNX_DIR / 'tts.json'\n</code></pre>"},{"location":"api/config/#supertonic.config.UNICODE_INDEXER_REL_PATH","title":"UNICODE_INDEXER_REL_PATH  <code>module-attribute</code>","text":"<pre><code>UNICODE_INDEXER_REL_PATH = ONNX_DIR / \"unicode_indexer.json\"\n</code></pre>"},{"location":"api/config/#supertonic.config.DP_ONNX_REL_PATH","title":"DP_ONNX_REL_PATH  <code>module-attribute</code>","text":"<pre><code>DP_ONNX_REL_PATH = ONNX_DIR / 'duration_predictor.onnx'\n</code></pre>"},{"location":"api/config/#supertonic.config.TEXT_ENC_ONNX_REL_PATH","title":"TEXT_ENC_ONNX_REL_PATH  <code>module-attribute</code>","text":"<pre><code>TEXT_ENC_ONNX_REL_PATH = ONNX_DIR / 'text_encoder.onnx'\n</code></pre>"},{"location":"api/config/#supertonic.config.VECTOR_EST_ONNX_REL_PATH","title":"VECTOR_EST_ONNX_REL_PATH  <code>module-attribute</code>","text":"<pre><code>VECTOR_EST_ONNX_REL_PATH = (\n    ONNX_DIR / \"vector_estimator.onnx\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.VOCODER_ONNX_REL_PATH","title":"VOCODER_ONNX_REL_PATH  <code>module-attribute</code>","text":"<pre><code>VOCODER_ONNX_REL_PATH = ONNX_DIR / 'vocoder.onnx'\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_TOTAL_STEPS","title":"DEFAULT_TOTAL_STEPS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_TOTAL_STEPS = 5\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_SPEED","title":"DEFAULT_SPEED  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SPEED = 1.05\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_MAX_CHUNK_LENGTH","title":"DEFAULT_MAX_CHUNK_LENGTH  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MAX_CHUNK_LENGTH = 300\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_SILENCE_DURATION","title":"DEFAULT_SILENCE_DURATION  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SILENCE_DURATION = 0.3\n</code></pre>"},{"location":"api/config/#supertonic.config.MIN_SPEED","title":"MIN_SPEED  <code>module-attribute</code>","text":"<pre><code>MIN_SPEED = 0.7\n</code></pre>"},{"location":"api/config/#supertonic.config.MAX_SPEED","title":"MAX_SPEED  <code>module-attribute</code>","text":"<pre><code>MAX_SPEED = 2.0\n</code></pre>"},{"location":"api/config/#supertonic.config.MIN_TOTAL_STEPS","title":"MIN_TOTAL_STEPS  <code>module-attribute</code>","text":"<pre><code>MIN_TOTAL_STEPS = 1\n</code></pre>"},{"location":"api/config/#supertonic.config.MAX_TOTAL_STEPS","title":"MAX_TOTAL_STEPS  <code>module-attribute</code>","text":"<pre><code>MAX_TOTAL_STEPS = 100\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_ONNX_PROVIDERS","title":"DEFAULT_ONNX_PROVIDERS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_ONNX_PROVIDERS = ['CPUExecutionProvider']\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_INTRA_OP_NUM_THREADS","title":"DEFAULT_INTRA_OP_NUM_THREADS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_INTRA_OP_NUM_THREADS = _parse_env_int(\n    \"SUPERTONIC_INTRA_OP_THREADS\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.DEFAULT_INTER_OP_NUM_THREADS","title":"DEFAULT_INTER_OP_NUM_THREADS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_INTER_OP_NUM_THREADS = _parse_env_int(\n    \"SUPERTONIC_INTER_OP_THREADS\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.MAX_TEXT_LENGTH","title":"MAX_TEXT_LENGTH  <code>module-attribute</code>","text":"<pre><code>MAX_TEXT_LENGTH = 100000\n</code></pre>"},{"location":"api/config/#supertonic.config.LOG_FORMAT","title":"LOG_FORMAT  <code>module-attribute</code>","text":"<pre><code>LOG_FORMAT = (\n    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\n</code></pre>"},{"location":"api/config/#supertonic.config.LOG_LEVEL","title":"LOG_LEVEL  <code>module-attribute</code>","text":"<pre><code>LOG_LEVEL = getenv('SUPERTONIC_LOG_LEVEL', 'INFO')\n</code></pre>"},{"location":"api/core/","title":"core","text":""},{"location":"api/core/#supertoniccore","title":"supertonic.core","text":""},{"location":"api/core/#supertonic.core","title":"supertonic.core","text":"<p>Core TTS engine and text processing components.</p> <p>This module contains the main Supertonic TTS engine, text processor, and supporting utilities for audio synthesis.</p> <p>Classes:</p> Name Description <code>UnicodeProcessor</code> <p>Processes text into unicode indices for the TTS model.</p> <code>Style</code> <p>Voice style representation for TTS synthesis.</p> <code>Supertonic</code> <p>Core TTS engine for Supertonic speech synthesis.</p> <p>Functions:</p> Name Description <code>length_to_mask</code> <p>Convert lengths to binary mask.</p> <code>get_latent_mask</code> <p>Generate mask for latent representations.</p> <p>Attributes:</p> Name Type Description <code>logger</code>"},{"location":"api/core/#supertonic.core.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/core/#supertonic.core.length_to_mask","title":"length_to_mask","text":"<pre><code>length_to_mask(\n    lengths: ndarray, max_len: Optional[int] = None\n) -&gt; ndarray\n</code></pre> <p>Convert lengths to binary mask.</p> <p>Parameters:</p> Name Type Description Default <code>lengths</code> <code>ndarray</code> <p>(B,)</p> required <code>max_len</code> <code>Optional[int]</code> <p>int</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mask</code> <code>ndarray</code> <p>(B, 1, max_len)</p> Source code in <code>supertonic/core.py</code> <pre><code>def length_to_mask(lengths: np.ndarray, max_len: Optional[int] = None) -&gt; np.ndarray:\n    \"\"\"\n    Convert lengths to binary mask.\n\n    Args:\n        lengths: (B,)\n        max_len: int\n\n    Returns:\n        mask: (B, 1, max_len)\n    \"\"\"\n    max_len = max_len or lengths.max()\n    ids = np.arange(0, max_len)\n    mask = (ids &lt; np.expand_dims(lengths, axis=1)).astype(np.float32)\n    return mask.reshape(-1, 1, max_len)\n</code></pre>"},{"location":"api/core/#supertonic.core.get_latent_mask","title":"get_latent_mask","text":"<pre><code>get_latent_mask(\n    wav_lengths: ndarray,\n    base_chunk_size: int,\n    chunk_compress_factor: int,\n) -&gt; ndarray\n</code></pre> <p>Generate mask for latent representations.</p> Source code in <code>supertonic/core.py</code> <pre><code>def get_latent_mask(\n    wav_lengths: np.ndarray, base_chunk_size: int, chunk_compress_factor: int\n) -&gt; np.ndarray:\n    \"\"\"Generate mask for latent representations.\"\"\"\n    latent_size = base_chunk_size * chunk_compress_factor\n    latent_lengths = (wav_lengths + latent_size - 1) // latent_size\n    latent_mask = length_to_mask(latent_lengths)\n    return latent_mask\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor","title":"UnicodeProcessor","text":"<pre><code>UnicodeProcessor(unicode_indexer_path: str)\n</code></pre> <p>Processes text into unicode indices for the TTS model.</p> <p>This class handles text preprocessing, normalization, and conversion to numeric indices that the TTS model can understand.</p> <p>Parameters:</p> Name Type Description Default <code>unicode_indexer_path</code> <code>str</code> <p>Path to the unicode indexer JSON file</p> required <p>Methods:</p> Name Description <code>validate_text</code> <p>Validate if text can be processed by the model.</p> <code>validate_text_list</code> <p>Validate a list of texts.</p> <p>Attributes:</p> Name Type Description <code>indexer</code> <code>supported_chars</code> <code>supported_character_set</code> <code>set[str]</code> Source code in <code>supertonic/core.py</code> <pre><code>def __init__(self, unicode_indexer_path: str):\n    self.indexer = self._load_indexer(unicode_indexer_path)\n    self.supported_chars = self._make_supported_characters()\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor.indexer","title":"indexer  <code>instance-attribute</code>","text":"<pre><code>indexer = _load_indexer(unicode_indexer_path)\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor.supported_chars","title":"supported_chars  <code>instance-attribute</code>","text":"<pre><code>supported_chars = _make_supported_characters()\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor.supported_character_set","title":"supported_character_set  <code>property</code>","text":"<pre><code>supported_character_set: set[str]\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor.validate_text","title":"validate_text","text":"<pre><code>validate_text(text: str) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validate if text can be processed by the model.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to validate</p> required <p>Returns:</p> Type Description <code>tuple[bool, list[str]]</code> <p>Tuple of (is_valid, unsupported_chars): - is_valid: True if text can be processed - unsupported_chars: List of unsupported characters (empty if valid)</p> Example <pre><code>processor = UnicodeProcessor(\"unicode_indexer.json\")\nis_valid, unsupported = processor.validate_text(\"Hello world\")\nif not is_valid:\n    print(f\"Cannot process: {unsupported}\")\n</code></pre> Source code in <code>supertonic/core.py</code> <pre><code>def validate_text(self, text: str) -&gt; tuple[bool, list[str]]:\n    \"\"\"Validate if text can be processed by the model.\n\n    Args:\n        text: Text to validate\n\n    Returns:\n        Tuple of (is_valid, unsupported_chars):\n            - is_valid: True if text can be processed\n            - unsupported_chars: List of unsupported characters (empty if valid)\n\n    Example:\n        ```python\n        processor = UnicodeProcessor(\"unicode_indexer.json\")\n        is_valid, unsupported = processor.validate_text(\"Hello world\")\n        if not is_valid:\n            print(f\"Cannot process: {unsupported}\")\n        ```\n    \"\"\"\n    input_chars = set(text)\n    unsupported_chars = set()\n    for input_char in input_chars:\n        p_chars = set(self._preprocess_text(input_char))\n        us_chars = p_chars - self.supported_character_set\n        if len(us_chars) &gt; 0:\n            unsupported_chars.update(input_char)\n    return len(unsupported_chars) == 0, sorted(list(unsupported_chars))\n</code></pre>"},{"location":"api/core/#supertonic.core.UnicodeProcessor.validate_text_list","title":"validate_text_list","text":"<pre><code>validate_text_list(\n    text_list: list[str],\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validate a list of texts.</p> Source code in <code>supertonic/core.py</code> <pre><code>def validate_text_list(self, text_list: list[str]) -&gt; tuple[bool, list[str]]:\n    \"\"\"Validate a list of texts.\"\"\"\n    text_cat = \"\".join(text_list)\n    return self.validate_text(text_cat)\n</code></pre>"},{"location":"api/core/#supertonic.core.Style","title":"Style","text":"<pre><code>Style(style_ttl_onnx: ndarray, style_dp_onnx: ndarray)\n</code></pre> <p>Voice style representation for TTS synthesis.</p> <p>This class encapsulates the style vectors used to control the voice characteristics during speech synthesis.</p> <p>Parameters:</p> Name Type Description Default <code>style_ttl_onnx</code> <code>ndarray</code> <p>Style vector for the text-to-latent model</p> required <code>style_dp_onnx</code> <code>ndarray</code> <p>Style vector for the duration predictor</p> required <p>Attributes:</p> Name Type Description <code>ttl</code> <code>ndarray</code> <p>Text-to-latent style vector</p> <code>dp</code> <code>ndarray</code> <p>Duration predictor style vector</p> Source code in <code>supertonic/core.py</code> <pre><code>def __init__(self, style_ttl_onnx: np.ndarray, style_dp_onnx: np.ndarray):\n    # Validate types\n    if not isinstance(style_ttl_onnx, np.ndarray):\n        raise TypeError(f\"style_ttl must be numpy array, got {type(style_ttl_onnx).__name__}\")\n    if not isinstance(style_dp_onnx, np.ndarray):\n        raise TypeError(f\"style_dp must be numpy array, got {type(style_dp_onnx).__name__}\")\n\n    self.ttl = style_ttl_onnx\n    self.dp = style_dp_onnx\n</code></pre>"},{"location":"api/core/#supertonic.core.Style.ttl","title":"ttl  <code>instance-attribute</code>","text":"<pre><code>ttl = style_ttl_onnx\n</code></pre>"},{"location":"api/core/#supertonic.core.Style.dp","title":"dp  <code>instance-attribute</code>","text":"<pre><code>dp = style_dp_onnx\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic","title":"Supertonic","text":"<pre><code>Supertonic(\n    cfgs: dict,\n    text_processor: UnicodeProcessor,\n    dp_ort: InferenceSession,\n    text_enc_ort: InferenceSession,\n    vector_est_ort: InferenceSession,\n    vocoder_ort: InferenceSession,\n)\n</code></pre> <p>Core TTS engine for Supertonic speech synthesis.</p> <p>This class orchestrates the entire text-to-speech pipeline, from text encoding through duration prediction and waveform generation.</p> <p>Parameters:</p> Name Type Description Default <code>cfgs</code> <code>dict</code> <p>Model configuration dictionary</p> required <code>text_processor</code> <code>UnicodeProcessor</code> <p>Unicode text processor instance</p> required <code>dp_ort</code> <code>InferenceSession</code> <p>Duration predictor ONNX session</p> required <code>text_enc_ort</code> <code>InferenceSession</code> <p>Text encoder ONNX session</p> required <code>vector_est_ort</code> <code>InferenceSession</code> <p>Vector estimator ONNX session</p> required <code>vocoder_ort</code> <code>InferenceSession</code> <p>Vocoder ONNX session</p> required <p>Attributes:</p> Name Type Description <code>sample_rate</code> <code>int</code> <p>Audio sample rate in Hz</p> <code>base_chunk_size</code> <code>int</code> <p>Base chunk size for latent representation</p> <code>chunk_compress_factor</code> <code>int</code> <p>Compression factor for chunks</p> <code>ldim</code> <code>int</code> <p>Latent dimension size</p> <p>Methods:</p> Name Description <code>sample_noisy_latent</code> Source code in <code>supertonic/core.py</code> <pre><code>def __init__(\n    self,\n    cfgs: dict,\n    text_processor: UnicodeProcessor,\n    dp_ort: ort.InferenceSession,\n    text_enc_ort: ort.InferenceSession,\n    vector_est_ort: ort.InferenceSession,\n    vocoder_ort: ort.InferenceSession,\n):\n    # Validate input types\n    if not isinstance(text_processor, UnicodeProcessor):\n        raise TypeError(\n            f\"text_processor must be UnicodeProcessor, got {type(text_processor).__name__}\"\n        )\n\n    for name, session in [\n        (\"dp_ort\", dp_ort),\n        (\"text_enc_ort\", text_enc_ort),\n        (\"vector_est_ort\", vector_est_ort),\n        (\"vocoder_ort\", vocoder_ort),\n    ]:\n        if not isinstance(session, ort.InferenceSession):\n            raise TypeError(f\"{name} must be InferenceSession, got {type(session).__name__}\")\n\n    self.cfgs = cfgs\n    self.text_processor = text_processor\n    self.dp_ort = dp_ort\n    self.text_enc_ort = text_enc_ort\n    self.vector_est_ort = vector_est_ort\n    self.vocoder_ort = vocoder_ort\n\n    try:\n        self.sample_rate = cfgs[\"ae\"][\"sample_rate\"]\n        self.base_chunk_size = cfgs[\"ae\"][\"base_chunk_size\"]\n        self.chunk_compress_factor = cfgs[\"ttl\"][\"chunk_compress_factor\"]\n        self.ldim = cfgs[\"ttl\"][\"latent_dim\"]\n    except KeyError as e:\n        logger.error(f\"Missing required config key: {e}\")\n        raise ValueError(\n            f\"Model configuration is incomplete. Missing key: {e}. \"\n            f\"Please ensure you have downloaded the correct model files.\"\n        ) from e\n\n    logger.info(\n        f\"Initialized Supertonic engine (sample_rate={self.sample_rate}Hz, \"\n        f\"latent_dim={self.ldim})\"\n    )\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.cfgs","title":"cfgs  <code>instance-attribute</code>","text":"<pre><code>cfgs = cfgs\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.text_processor","title":"text_processor  <code>instance-attribute</code>","text":"<pre><code>text_processor = text_processor\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.dp_ort","title":"dp_ort  <code>instance-attribute</code>","text":"<pre><code>dp_ort = dp_ort\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.text_enc_ort","title":"text_enc_ort  <code>instance-attribute</code>","text":"<pre><code>text_enc_ort = text_enc_ort\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.vector_est_ort","title":"vector_est_ort  <code>instance-attribute</code>","text":"<pre><code>vector_est_ort = vector_est_ort\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.vocoder_ort","title":"vocoder_ort  <code>instance-attribute</code>","text":"<pre><code>vocoder_ort = vocoder_ort\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.sample_rate","title":"sample_rate  <code>instance-attribute</code>","text":"<pre><code>sample_rate = cfgs['ae']['sample_rate']\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.base_chunk_size","title":"base_chunk_size  <code>instance-attribute</code>","text":"<pre><code>base_chunk_size = cfgs['ae']['base_chunk_size']\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.chunk_compress_factor","title":"chunk_compress_factor  <code>instance-attribute</code>","text":"<pre><code>chunk_compress_factor = cfgs[\"ttl\"][\"chunk_compress_factor\"]\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.ldim","title":"ldim  <code>instance-attribute</code>","text":"<pre><code>ldim = cfgs['ttl']['latent_dim']\n</code></pre>"},{"location":"api/core/#supertonic.core.Supertonic.sample_noisy_latent","title":"sample_noisy_latent","text":"<pre><code>sample_noisy_latent(\n    duration: ndarray,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> Source code in <code>supertonic/core.py</code> <pre><code>def sample_noisy_latent(self, duration: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray]:\n    bsz = len(duration)\n    wav_len_max = duration.max() * self.sample_rate\n    wav_lengths = (duration * self.sample_rate).astype(np.int64)\n    chunk_size = self.base_chunk_size * self.chunk_compress_factor\n    latent_len = ((wav_len_max + chunk_size - 1) / chunk_size).astype(np.int32)\n    latent_dim = self.ldim * self.chunk_compress_factor\n    noisy_latent = np.random.randn(bsz, latent_dim, latent_len).astype(np.float32)\n    latent_mask = get_latent_mask(wav_lengths, self.base_chunk_size, self.chunk_compress_factor)\n    noisy_latent = noisy_latent * latent_mask\n    return noisy_latent, latent_mask\n</code></pre>"},{"location":"api/loader/","title":"loader","text":""},{"location":"api/loader/#supertonicloader","title":"supertonic.loader","text":""},{"location":"api/loader/#supertonic.loader","title":"supertonic.loader","text":"<p>Model loading and voice style management utilities.</p> <p>This module handles downloading, loading, and managing Supertonic TTS models and voice styles from HuggingFace Hub.</p> <p>Functions:</p> Name Description <code>get_cache_dir</code> <p>Get or create the default cache directory for Supertonic models.</p> <code>get_all_onnx_module_relative_paths</code> <p>Get list of all required ONNX model file paths.</p> <code>has_all_onnx_modules</code> <p>Check if all required ONNX model files exist in the directory.</p> <code>download_model</code> <p>Download Supertonic model from HuggingFace Hub.</p> <code>load_configs</code> <p>Load model configuration from JSON file.</p> <code>load_onnx_modules</code> <p>Load all ONNX model modules for TTS synthesis.</p> <code>load_text_processor</code> <p>Load the unicode text processor for the model.</p> <code>load_model</code> <p>Load the complete Supertonic TTS model.</p> <code>list_available_voice_style_paths</code> <p>List all available voice style JSON files in the model directory.</p> <code>list_available_voice_style_names</code> <p>List names of all available voice styles.</p> <code>load_voice_style_from_json_file</code> <p>Load a voice style from a JSON file.</p> <code>load_voice_style_from_name</code> <p>Load a voice style by name from the model directory.</p> <p>Attributes:</p> Name Type Description <code>logger</code>"},{"location":"api/loader/#supertonic.loader.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/loader/#supertonic.loader.get_cache_dir","title":"get_cache_dir","text":"<pre><code>get_cache_dir() -&gt; Path\n</code></pre> <p>Get or create the default cache directory for Supertonic models.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path object pointing to the cache directory</p> Note <p>Default location is ~/.cache/supertonic, but can be overridden with SUPERTONIC_CACHE_DIR environment variable</p> Source code in <code>supertonic/loader.py</code> <pre><code>def get_cache_dir() -&gt; Path:\n    \"\"\"Get or create the default cache directory for Supertonic models.\n\n    Returns:\n        Path object pointing to the cache directory\n\n    Note:\n        Default location is ~/.cache/supertonic, but can be overridden\n        with SUPERTONIC_CACHE_DIR environment variable\n    \"\"\"\n    cache_dir = Path(DEFAULT_CACHE_DIR)\n    cache_dir.mkdir(parents=True, exist_ok=True)\n    logger.debug(f\"Using cache directory: {cache_dir}\")\n    return cache_dir\n</code></pre>"},{"location":"api/loader/#supertonic.loader.get_all_onnx_module_relative_paths","title":"get_all_onnx_module_relative_paths","text":"<pre><code>get_all_onnx_module_relative_paths() -&gt; list[Path]\n</code></pre> <p>Get list of all required ONNX model file paths.</p> <p>Returns:</p> Type Description <code>list[Path]</code> <p>List of Path objects for each required ONNX model file</p> Source code in <code>supertonic/loader.py</code> <pre><code>def get_all_onnx_module_relative_paths() -&gt; list[Path]:\n    \"\"\"Get list of all required ONNX model file paths.\n\n    Returns:\n        List of Path objects for each required ONNX model file\n    \"\"\"\n    return [\n        DP_ONNX_REL_PATH,\n        TEXT_ENC_ONNX_REL_PATH,\n        VECTOR_EST_ONNX_REL_PATH,\n        VOCODER_ONNX_REL_PATH,\n    ]\n</code></pre>"},{"location":"api/loader/#supertonic.loader.has_all_onnx_modules","title":"has_all_onnx_modules","text":"<pre><code>has_all_onnx_modules(model_dir: Union[Path, str]) -&gt; bool\n</code></pre> <p>Check if all required ONNX model files exist in the directory.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory to check for model files (str or Path)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all required ONNX files exist, False otherwise</p> Source code in <code>supertonic/loader.py</code> <pre><code>def has_all_onnx_modules(model_dir: Union[Path, str]) -&gt; bool:\n    \"\"\"Check if all required ONNX model files exist in the directory.\n\n    Args:\n        model_dir: Directory to check for model files (str or Path)\n\n    Returns:\n        True if all required ONNX files exist, False otherwise\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n    module_rel_paths = get_all_onnx_module_relative_paths()\n    all_exist = all((model_dir / path).exists() for path in module_rel_paths)\n\n    if not all_exist:\n        missing = [str(path) for path in module_rel_paths if not (model_dir / path).exists()]\n        logger.debug(f\"Missing ONNX files: {missing}\")\n\n    return all_exist\n</code></pre>"},{"location":"api/loader/#supertonic.loader.download_model","title":"download_model","text":"<pre><code>download_model(model_dir: Union[Path, str]) -&gt; None\n</code></pre> <p>Download Supertonic model from HuggingFace Hub.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory where the model should be downloaded (str or Path)</p> required Source code in <code>supertonic/loader.py</code> <pre><code>def download_model(model_dir: Union[Path, str]) -&gt; None:\n    \"\"\"Download Supertonic model from HuggingFace Hub.\n\n    Args:\n        model_dir: Directory where the model should be downloaded (str or Path)\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n\n    # Use temporary directory for atomic download\n    temp_dir = model_dir.parent / f\".{model_dir.name}.tmp\"\n\n    try:\n        from huggingface_hub import snapshot_download\n\n        logger.info(\n            f\"Downloading model from {DEFAULT_MODEL_REPO} to temporary location: {temp_dir}\"\n        )\n        snapshot_download(\n            repo_id=DEFAULT_MODEL_REPO, local_dir=str(temp_dir), revision=DEFAULT_MODEL_REVISION\n        )\n\n        # Move from temporary to final location on success\n        if model_dir.exists():\n            logger.info(f\"Removing existing model directory: {model_dir}\")\n            shutil.rmtree(model_dir)\n        shutil.move(str(temp_dir), str(model_dir))\n\n        logger.info(\"Model download completed successfully\")\n\n    except ImportError as e:\n        logger.error(\"huggingface_hub not installed\")\n        raise RuntimeError(\n            \"Failed to import huggingface_hub. Please install it with: \"\n            \"pip install huggingface-hub\"\n        ) from e\n    except Exception as e:\n        logger.error(f\"Model download failed: {e}\")\n\n        # Clean up temporary files on failure\n        if temp_dir.exists():\n            logger.info(\"Cleaning up temporary files...\")\n            try:\n                shutil.rmtree(temp_dir)\n            except Exception as cleanup_error:\n                logger.warning(f\"Failed to clean up temporary files: {cleanup_error}\")\n\n        raise RuntimeError(\n            f\"Failed to download model from {DEFAULT_MODEL_REPO}. \"\n            f\"Please check your internet connection and try again. \"\n            f\"Error: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_configs","title":"load_configs","text":"<pre><code>load_configs(model_dir: Union[Path, str]) -&gt; dict\n</code></pre> <p>Load model configuration from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the model files (str or Path)</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing model configuration</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_configs(model_dir: Union[Path, str]) -&gt; dict:\n    \"\"\"Load model configuration from JSON file.\n\n    Args:\n        model_dir: Directory containing the model files (str or Path)\n\n    Returns:\n        Dictionary containing model configuration\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n    cfg_path = model_dir / CFG_REL_PATH\n\n    if not cfg_path.exists():\n        logger.error(f\"Config file not found: {cfg_path}\")\n        raise FileNotFoundError(\n            f\"Model configuration file not found at {cfg_path}. \"\n            f\"Please ensure the model is properly downloaded.\"\n        )\n\n    try:\n        with open(cfg_path, \"r\") as f:\n            cfgs = json.load(f)\n        logger.debug(f\"Loaded config from {cfg_path}\")\n        return cfgs\n    except json.JSONDecodeError as e:\n        logger.error(f\"Invalid config format: {e}\")\n        raise ValueError(\n            f\"Model configuration file is malformed at {cfg_path}. \"\n            f\"Please re-download the model.\"\n        ) from e\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_onnx_modules","title":"load_onnx_modules","text":"<pre><code>load_onnx_modules(\n    model_dir: Union[Path, str],\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n) -&gt; tuple[\n    InferenceSession,\n    InferenceSession,\n    InferenceSession,\n    InferenceSession,\n]\n</code></pre> <p>Load all ONNX model modules for TTS synthesis.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the ONNX model files (str or Path)</p> required <code>intra_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for intra-op parallelism. None (default) lets ONNX Runtime auto-detect optimal value</p> <code>None</code> <code>inter_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for inter-op parallelism. None (default) lets ONNX Runtime auto-detect optimal value</p> <code>None</code> <p>Returns:</p> Type Description <code>InferenceSession</code> <p>Tuple of (duration_predictor, text_encoder, vector_estimator, vocoder)</p> <code>InferenceSession</code> <p>ONNX Runtime inference sessions</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_onnx_modules(\n    model_dir: Union[Path, str],\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n) -&gt; tuple[\n    ort.InferenceSession,\n    ort.InferenceSession,\n    ort.InferenceSession,\n    ort.InferenceSession,\n]:\n    \"\"\"Load all ONNX model modules for TTS synthesis.\n\n    Args:\n        model_dir: Directory containing the ONNX model files (str or Path)\n        intra_op_num_threads: Number of threads for intra-op parallelism.\n            None (default) lets ONNX Runtime auto-detect optimal value\n        inter_op_num_threads: Number of threads for inter-op parallelism.\n            None (default) lets ONNX Runtime auto-detect optimal value\n\n    Returns:\n        Tuple of (duration_predictor, text_encoder, vector_estimator, vocoder)\n        ONNX Runtime inference sessions\n    \"\"\"\n\n    def _load_onnx(\n        onnx_path: Path, opts: ort.SessionOptions, providers: list[str]\n    ) -&gt; ort.InferenceSession:\n        \"\"\"Load a single ONNX model file.\"\"\"\n        if not onnx_path.exists():\n            raise FileNotFoundError(\n                f\"ONNX model file not found: {onnx_path}. \"\n                f\"Please ensure the model is properly downloaded.\"\n            )\n\n        logger.debug(f\"Loading ONNX model: {onnx_path}\")\n        return ort.InferenceSession(onnx_path, sess_options=opts, providers=providers)\n\n    opts = ort.SessionOptions()\n    # Performance optimizations\n    opts.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n    opts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n\n    # Only set thread counts if explicitly specified\n    # Otherwise, let ONNX Runtime automatically determine optimal values\n    intra_threads = (\n        intra_op_num_threads if intra_op_num_threads is not None else DEFAULT_INTRA_OP_NUM_THREADS\n    )\n    inter_threads = (\n        inter_op_num_threads if inter_op_num_threads is not None else DEFAULT_INTER_OP_NUM_THREADS\n    )\n\n    if intra_threads is not None:\n        opts.intra_op_num_threads = intra_threads\n    if inter_threads is not None:\n        opts.inter_op_num_threads = inter_threads\n\n    # Setup execution providers with fallback to CPU\n    providers = DEFAULT_ONNX_PROVIDERS\n    available_providers = ort.get_available_providers()\n\n    # Filter to only use available providers\n    valid_providers = [p for p in providers if p in available_providers]\n    if not valid_providers:\n        logger.warning(\n            f\"Requested providers {providers} not available. \"\n            f\"Falling back to CPUExecutionProvider\"\n        )\n        valid_providers = [\"CPUExecutionProvider\"]\n    else:\n        logger.info(f\"Using ONNX providers: {valid_providers}\")\n\n    thread_info = (\n        f\"intra_threads={intra_threads if intra_threads is not None else 'auto'}, \"\n        f\"inter_threads={inter_threads if inter_threads is not None else 'auto'}\"\n    )\n    logger.info(f\"ONNX Runtime config: {thread_info}\")\n\n    dp_onnx_path = model_dir / DP_ONNX_REL_PATH\n    text_enc_onnx_path = model_dir / TEXT_ENC_ONNX_REL_PATH\n    vector_est_onnx_path = model_dir / VECTOR_EST_ONNX_REL_PATH\n    vocoder_onnx_path = model_dir / VOCODER_ONNX_REL_PATH\n\n    logger.info(f\"Loading ONNX models with providers: {valid_providers}\")\n    dp_ort = _load_onnx(dp_onnx_path, opts, valid_providers)\n    text_enc_ort = _load_onnx(text_enc_onnx_path, opts, valid_providers)\n    vector_est_ort = _load_onnx(vector_est_onnx_path, opts, valid_providers)\n    vocoder_ort = _load_onnx(vocoder_onnx_path, opts, valid_providers)\n\n    logger.info(\"Successfully loaded all ONNX models\")\n    return dp_ort, text_enc_ort, vector_est_ort, vocoder_ort\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_text_processor","title":"load_text_processor","text":"<pre><code>load_text_processor(\n    model_dir: Union[Path, str],\n) -&gt; UnicodeProcessor\n</code></pre> <p>Load the unicode text processor for the model.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the model files (str or Path)</p> required <p>Returns:</p> Type Description <code>UnicodeProcessor</code> <p>Initialized UnicodeProcessor instance</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_text_processor(model_dir: Union[Path, str]) -&gt; UnicodeProcessor:\n    \"\"\"Load the unicode text processor for the model.\n\n    Args:\n        model_dir: Directory containing the model files (str or Path)\n\n    Returns:\n        Initialized UnicodeProcessor instance\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n    unicode_indexer_path = model_dir / UNICODE_INDEXER_REL_PATH\n    logger.debug(f\"Loading text processor from {unicode_indexer_path}\")\n    text_processor = UnicodeProcessor(str(unicode_indexer_path))\n    return text_processor\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_model","title":"load_model","text":"<pre><code>load_model(\n    model_dir: Union[Path, str],\n    auto_download: bool,\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n) -&gt; Supertonic\n</code></pre> <p>Load the complete Supertonic TTS model.</p> <p>This function loads all model components including ONNX modules, configuration, and text processor. If model files are missing and auto_download is enabled, it will download them from HuggingFace Hub.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing (or to contain) the model files (str or Path)</p> required <code>auto_download</code> <code>bool</code> <p>If True, automatically download missing model files</p> required <code>intra_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for intra-op parallelism. None (default) lets ONNX Runtime auto-detect optimal value</p> <code>None</code> <code>inter_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for inter-op parallelism. None (default) lets ONNX Runtime auto-detect optimal value</p> <code>None</code> <p>Returns:</p> Type Description <code>Supertonic</code> <p>Initialized Supertonic TTS engine</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_model(\n    model_dir: Union[Path, str],\n    auto_download: bool,\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n) -&gt; Supertonic:\n    \"\"\"Load the complete Supertonic TTS model.\n\n    This function loads all model components including ONNX modules,\n    configuration, and text processor. If model files are missing and\n    auto_download is enabled, it will download them from HuggingFace Hub.\n\n    Args:\n        model_dir: Directory containing (or to contain) the model files (str or Path)\n        auto_download: If True, automatically download missing model files\n        intra_op_num_threads: Number of threads for intra-op parallelism.\n            None (default) lets ONNX Runtime auto-detect optimal value\n        inter_op_num_threads: Number of threads for inter-op parallelism.\n            None (default) lets ONNX Runtime auto-detect optimal value\n\n    Returns:\n        Initialized Supertonic TTS engine\n    \"\"\"\n    logger.info(f\"Loading model from {model_dir}\")\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n\n    if not has_all_onnx_modules(model_dir):\n        if not auto_download:\n            logger.error(f\"ONNX models not found in {model_dir}\")\n            raise FileNotFoundError(\n                f\"ONNX model files not found in {model_dir}. \"\n                f\"Set auto_download=True to automatically download from HuggingFace Hub, \"\n                f\"or manually download the model to this directory.\"\n            )\n        download_model(model_dir)\n\n    cfgs = load_configs(model_dir)\n    dp_ort, text_enc_ort, vector_est_ort, vocoder_ort = load_onnx_modules(\n        model_dir, intra_op_num_threads, inter_op_num_threads\n    )\n    text_processor = load_text_processor(model_dir)\n\n    logger.info(\"Model loaded successfully\")\n    return Supertonic(cfgs, text_processor, dp_ort, text_enc_ort, vector_est_ort, vocoder_ort)\n</code></pre>"},{"location":"api/loader/#supertonic.loader.list_available_voice_style_paths","title":"list_available_voice_style_paths","text":"<pre><code>list_available_voice_style_paths(\n    model_dir: Union[Path, str],\n) -&gt; list[Path]\n</code></pre> <p>List all available voice style JSON files in the model directory.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the model files (str or Path)</p> required <p>Returns:</p> Type Description <code>list[Path]</code> <p>Sorted list of paths to voice style JSON files</p> Source code in <code>supertonic/loader.py</code> <pre><code>def list_available_voice_style_paths(model_dir: Union[Path, str]) -&gt; list[Path]:\n    \"\"\"List all available voice style JSON files in the model directory.\n\n    Args:\n        model_dir: Directory containing the model files (str or Path)\n\n    Returns:\n        Sorted list of paths to voice style JSON files\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n    voice_styles_dir = model_dir / VOICE_STYLES_DIR\n\n    if not voice_styles_dir.exists():\n        logger.error(f\"Voice styles directory not found: {voice_styles_dir}\")\n        raise FileNotFoundError(\n            f\"Voice styles directory not found at {voice_styles_dir}. \"\n            f\"Please ensure the model is properly downloaded.\"\n        )\n\n    paths = sorted(list(voice_styles_dir.glob(\"*.json\")))\n    logger.debug(f\"Found {len(paths)} voice styles in {voice_styles_dir}\")\n    return paths\n</code></pre>"},{"location":"api/loader/#supertonic.loader.list_available_voice_style_names","title":"list_available_voice_style_names","text":"<pre><code>list_available_voice_style_names(\n    model_dir: Union[Path, str],\n) -&gt; list[str]\n</code></pre> <p>List names of all available voice styles.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the model files (str or Path)</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of voice style names (without .json extension)</p> Source code in <code>supertonic/loader.py</code> <pre><code>def list_available_voice_style_names(model_dir: Union[Path, str]) -&gt; list[str]:\n    \"\"\"List names of all available voice styles.\n\n    Args:\n        model_dir: Directory containing the model files (str or Path)\n\n    Returns:\n        List of voice style names (without .json extension)\n    \"\"\"\n    voice_style_paths = list_available_voice_style_paths(model_dir)\n    names = [path.stem for path in voice_style_paths]\n    return names\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_voice_style_from_json_file","title":"load_voice_style_from_json_file","text":"<pre><code>load_voice_style_from_json_file(\n    voice_style_path: Union[Path, str],\n) -&gt; Style\n</code></pre> <p>Load a voice style from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>voice_style_path</code> <code>Union[Path, str]</code> <p>Path to the voice style JSON file (str or Path)</p> required <p>Returns:</p> Type Description <code>Style</code> <p>Style object with loaded style vectors</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_voice_style_from_json_file(voice_style_path: Union[Path, str]) -&gt; Style:\n    \"\"\"Load a voice style from a JSON file.\n\n    Args:\n        voice_style_path: Path to the voice style JSON file (str or Path)\n\n    Returns:\n        Style object with loaded style vectors\n    \"\"\"\n    # Convert to Path if string\n    voice_style_path = Path(voice_style_path)\n\n    def _load_style_from_json(json_data: dict) -&gt; np.ndarray:\n        \"\"\"Parse style vector from JSON data.\"\"\"\n        try:\n            dims = json_data[\"dims\"]\n            data = json_data[\"data\"]\n            return np.array(data, dtype=np.float32).reshape(*dims)\n        except KeyError as e:\n            raise ValueError(f\"Invalid style format: missing key {e}\") from e\n\n    if not voice_style_path.exists():\n        raise FileNotFoundError(f\"Voice style file not found: {voice_style_path}\")\n\n    try:\n        with open(voice_style_path, \"r\") as f:\n            voice_style_json = json.load(f)\n\n        # Validate voice style format\n        if not validate_voice_style_format(voice_style_json):\n            raise ValueError(\n                f\"Invalid voice style format in {voice_style_path}. \"\n                f\"Expected 'style_ttl' and 'style_dp' with 'dims' and 'data' fields.\"\n            )\n\n        logger.debug(f\"Loading voice style from {voice_style_path}\")\n        ttl_style = _load_style_from_json(voice_style_json[\"style_ttl\"])\n        dp_style = _load_style_from_json(voice_style_json[\"style_dp\"])\n\n        return Style(ttl_style, dp_style)\n\n    except json.JSONDecodeError as e:\n        logger.error(f\"Invalid JSON in voice style file: {e}\")\n        raise ValueError(\n            f\"Voice style file is malformed at {voice_style_path}. \"\n            f\"Please check the file format.\"\n        ) from e\n    except (KeyError, ValueError) as e:\n        logger.error(f\"Invalid voice style format: {e}\")\n        raise ValueError(\n            f\"Voice style file has invalid format at {voice_style_path}. \"\n            f\"Expected 'style_ttl' and 'style_dp' fields. Error: {e}\"\n        ) from e\n</code></pre>"},{"location":"api/loader/#supertonic.loader.load_voice_style_from_name","title":"load_voice_style_from_name","text":"<pre><code>load_voice_style_from_name(\n    model_dir: Union[Path, str], voice_name: str\n) -&gt; Style\n</code></pre> <p>Load a voice style by name from the model directory.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing the model files (str or Path)</p> required <code>voice_name</code> <code>str</code> <p>Name of the voice style (without .json extension)</p> required <p>Returns:</p> Type Description <code>Style</code> <p>Style object with loaded style vectors</p> Source code in <code>supertonic/loader.py</code> <pre><code>def load_voice_style_from_name(model_dir: Union[Path, str], voice_name: str) -&gt; Style:\n    \"\"\"Load a voice style by name from the model directory.\n\n    Args:\n        model_dir: Directory containing the model files (str or Path)\n        voice_name: Name of the voice style (without .json extension)\n\n    Returns:\n        Style object with loaded style vectors\n    \"\"\"\n    model_dir = Path(model_dir) if isinstance(model_dir, str) else model_dir\n    voice_style_path = model_dir / VOICE_STYLES_DIR / f\"{voice_name}.json\"\n\n    if not voice_style_path.exists():\n        available = list_available_voice_style_names(model_dir)\n        logger.error(f\"Voice style '{voice_name}' not found\")\n        raise FileNotFoundError(\n            f\"Voice style '{voice_name}' not found. \"\n            f\"Available voice styles: {', '.join(available)}\"\n        )\n\n    return load_voice_style_from_json_file(voice_style_path)\n</code></pre>"},{"location":"api/pipeline/","title":"pipeline","text":""},{"location":"api/pipeline/#supertonicpipeline","title":"supertonic.pipeline","text":""},{"location":"api/pipeline/#supertonic.pipeline","title":"supertonic.pipeline","text":"<p>High-level TTS interface for Supertonic.</p> <p>This module provides the main TTS class for easy text-to-speech synthesis with automatic model loading and voice style management.</p> <p>Classes:</p> Name Description <code>TTS</code> <p>High-level interface for Supertonic text-to-speech synthesis.</p> <p>Attributes:</p> Name Type Description <code>logger</code>"},{"location":"api/pipeline/#supertonic.pipeline.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS","title":"TTS","text":"<pre><code>TTS(\n    model_dir: Optional[Union[Path, str]] = None,\n    auto_download: bool = True,\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n)\n</code></pre> <p>High-level interface for Supertonic text-to-speech synthesis.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Optional[Union[Path, str]]</code> <p>Directory containing model files. If None, uses default cache directory (~/.cache/supertonic)</p> <code>None</code> <code>auto_download</code> <code>bool</code> <p>If True, automatically downloads model files from HuggingFace Hub if they're missing</p> <code>True</code> <code>intra_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for intra-op parallelism. If None (default), ONNX Runtime automatically determines optimal value based on your system. Can also be set via SUPERTONIC_INTRA_OP_THREADS environment variable</p> <code>None</code> <code>inter_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for inter-op parallelism. If None (default), ONNX Runtime automatically determines optimal value based on your system. Can also be set via SUPERTONIC_INTER_OP_THREADS environment variable</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>model</code> <code>Supertonic</code> <p>The underlying Supertonic engine</p> <code>model_dir</code> <code>Path</code> <p>Path to the model directory</p> <code>sample_rate</code> <code>int</code> <p>Audio sample rate in Hz</p> <code>voice_style_names</code> <code>list[str]</code> <p>List of available voice style names</p> Example <pre><code>from supertonic import TTS\ntts = TTS()\nstyle = tts.get_voice_style(\"M1\")\nwav, dur = tts.synthesize(\"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\", voice_style=style)\ntts.save_audio(wav, \"output.wav\")\n</code></pre> <p>Initialize the TTS engine.</p> <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Union[Path, str]</code> <p>Directory containing model files. If None, uses default cache directory</p> <code>None</code> <code>auto_download</code> <code>bool</code> <p>If True, automatically downloads missing model files</p> <code>True</code> <code>intra_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for intra-op parallelism. If None (default), ONNX Runtime automatically determines optimal value based on your system. Can also be set via SUPERTONIC_INTRA_OP_THREADS environment variable</p> <code>None</code> <code>inter_op_num_threads</code> <code>Optional[int]</code> <p>Number of threads for inter-op parallelism. If None (default), ONNX Runtime automatically determines optimal value based on your system. Can also be set via SUPERTONIC_INTER_OP_THREADS environment variable</p> <code>None</code> <p>Methods:</p> Name Description <code>get_voice_style</code> <p>Load a voice style by name. Avaliable voice style names can be listed with</p> <code>get_voice_style_from_path</code> <p>Load a voice style from a JSON file path.</p> <code>synthesize</code> <p>Synthesize speech from text.</p> <code>save_audio</code> <p>Save synthesized audio to a WAV file.</p> Source code in <code>supertonic/pipeline.py</code> <pre><code>def __init__(\n    self,\n    model_dir: Optional[Union[Path, str]] = None,\n    auto_download: bool = True,\n    intra_op_num_threads: Optional[int] = None,\n    inter_op_num_threads: Optional[int] = None,\n):\n    \"\"\"Initialize the TTS engine.\n\n    Args:\n        model_dir (Union[Path, str]): Directory containing model files. If None, uses default\n            cache directory\n        auto_download: If True, automatically downloads missing model files\n        intra_op_num_threads: Number of threads for intra-op parallelism.\n            If None (default), ONNX Runtime automatically determines optimal value based on your system.\n            Can also be set via SUPERTONIC_INTRA_OP_THREADS environment variable\n        inter_op_num_threads: Number of threads for inter-op parallelism.\n            If None (default), ONNX Runtime automatically determines optimal value based on your system.\n            Can also be set via SUPERTONIC_INTER_OP_THREADS environment variable\n    \"\"\"\n    if model_dir is None:\n        model_dir = get_cache_dir()\n\n    if not isinstance(model_dir, Path):\n        model_dir = Path(model_dir)\n\n    self.model = load_model(\n        model_dir, auto_download, intra_op_num_threads, inter_op_num_threads\n    )\n    self.model_dir = model_dir\n    self.sample_rate = self.model.sample_rate\n    self.voice_style_names = list_available_voice_style_names(model_dir)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = load_model(\n    model_dir,\n    auto_download,\n    intra_op_num_threads,\n    inter_op_num_threads,\n)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.model_dir","title":"model_dir  <code>instance-attribute</code>","text":"<pre><code>model_dir = model_dir\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.sample_rate","title":"sample_rate  <code>instance-attribute</code>","text":"<pre><code>sample_rate = sample_rate\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.voice_style_names","title":"voice_style_names  <code>instance-attribute</code>","text":"<pre><code>voice_style_names = list_available_voice_style_names(\n    model_dir\n)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.get_voice_style","title":"get_voice_style","text":"<pre><code>get_voice_style(voice_name: str) -&gt; Style\n</code></pre> <p>Load a voice style by name. Avaliable voice style names can be listed with     <code>list_available_voice_style_names()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>voice_name</code> <code>str</code> <p>Name of the voice style (e.g., 'M1', 'F1', 'M2', 'F2')</p> required <p>Returns:</p> Type Description <code>Style</code> <p>Style object containing voice style vectors</p> Source code in <code>supertonic/pipeline.py</code> <pre><code>def get_voice_style(self, voice_name: str) -&gt; Style:\n    \"\"\"Load a voice style by name. Avaliable voice style names can be listed with\n        `list_available_voice_style_names()`.\n\n    Args:\n        voice_name: Name of the voice style (e.g., 'M1', 'F1', 'M2', 'F2')\n\n    Returns:\n        Style object containing voice style vectors\n    \"\"\"\n    return load_voice_style_from_name(self.model_dir, voice_name)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.get_voice_style_from_path","title":"get_voice_style_from_path","text":"<pre><code>get_voice_style_from_path(\n    voice_style_path: Union[Path, str],\n) -&gt; Style\n</code></pre> <p>Load a voice style from a JSON file path.</p> <p>Parameters:</p> Name Type Description Default <code>voice_style_path</code> <code>Union[Path, str]</code> <p>Path to the voice style JSON file (str or Path)</p> required <p>Returns:</p> Type Description <code>Style</code> <p>Style object containing voice style vectors</p> Source code in <code>supertonic/pipeline.py</code> <pre><code>def get_voice_style_from_path(self, voice_style_path: Union[Path, str]) -&gt; Style:\n    \"\"\"Load a voice style from a JSON file path.\n\n    Args:\n        voice_style_path: Path to the voice style JSON file (str or Path)\n\n    Returns:\n        Style object containing voice style vectors\n    \"\"\"\n    return load_voice_style_from_json_file(voice_style_path)\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.synthesize","title":"synthesize","text":"<pre><code>synthesize(\n    text: str,\n    voice_style: Style,\n    total_steps: int = DEFAULT_TOTAL_STEPS,\n    speed: float = DEFAULT_SPEED,\n    max_chunk_length: int = DEFAULT_MAX_CHUNK_LENGTH,\n    silence_duration: float = DEFAULT_SILENCE_DURATION,\n    verbose: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Synthesize speech from text.</p> <p>This method automatically chunks long text into smaller segments and concatenates them with silence in between.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to synthesize</p> required <code>voice_style</code> <code>Style</code> <p>Voice style object</p> required <code>total_steps</code> <code>int</code> <p>Number of synthesis steps (default: 5)</p> <code>DEFAULT_TOTAL_STEPS</code> <code>speed</code> <code>float</code> <p>Speech speed multiplier (default: 1.05)</p> <code>DEFAULT_SPEED</code> <code>max_chunk_length</code> <code>int</code> <p>Max characters per chunk (default: 300)</p> <code>DEFAULT_MAX_CHUNK_LENGTH</code> <code>silence_duration</code> <code>float</code> <p>Silence between chunks in seconds (default: 0.3)</p> <code>DEFAULT_SILENCE_DURATION</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed progress information (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>Tuple of (waveform, duration): - waveform: Audio array of shape (1, num_samples) - duration: Total duration in seconds</p> Example <pre><code>tts = TTS()\nstyle = tts.get_voice_style(\"M1\")\nwav, dur = tts.synthesize(\"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\", voice_style=style, total_steps=5)\nprint(f\"Generated {dur[0]:.2f}s of audio\")\n</code></pre> Source code in <code>supertonic/pipeline.py</code> <pre><code>def synthesize(\n    self,\n    text: str,\n    voice_style: Style,\n    total_steps: int = DEFAULT_TOTAL_STEPS,\n    speed: float = DEFAULT_SPEED,\n    max_chunk_length: int = DEFAULT_MAX_CHUNK_LENGTH,\n    silence_duration: float = DEFAULT_SILENCE_DURATION,\n    verbose: bool = False,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Synthesize speech from text.\n\n    This method automatically chunks long text into smaller segments\n    and concatenates them with silence in between.\n\n    Args:\n        text: Text to synthesize\n        voice_style: Voice style object\n        total_steps: Number of synthesis steps (default: 5)\n        speed: Speech speed multiplier (default: 1.05)\n        max_chunk_length: Max characters per chunk (default: 300)\n        silence_duration: Silence between chunks in seconds (default: 0.3)\n        verbose: If True, print detailed progress information (default: False)\n\n    Returns:\n        Tuple of (waveform, duration):\n            - waveform: Audio array of shape (1, num_samples)\n            - duration: Total duration in seconds\n\n    Example:\n        ```python\n        tts = TTS()\n        style = tts.get_voice_style(\"M1\")\n        wav, dur = tts.synthesize(\"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\", voice_style=style, total_steps=5)\n        print(f\"Generated {dur[0]:.2f}s of audio\")\n        ```\n    \"\"\"\n    # Validate inputs\n    if not text or not text.strip():\n        raise ValueError(\"Text cannot be empty\")\n\n    if verbose:\n        print(f\"\ud83d\udcdd Input text length: {len(text)} characters\")\n\n    if len(text) &gt; MAX_TEXT_LENGTH:\n        raise ValueError(\n            f\"Text length ({len(text)}) exceeds maximum allowed length \"\n            f\"({MAX_TEXT_LENGTH}). Please split your text into smaller chunks.\"\n        )\n\n    if not isinstance(voice_style, Style):\n        raise TypeError(\n            f\"voice_style must be a Style object, got {type(voice_style).__name__}. \"\n            f\"Use get_voice_style() to load a style.\"\n        )\n\n    if not (total_steps &gt;= MIN_TOTAL_STEPS and total_steps &lt;= MAX_TOTAL_STEPS):\n        raise ValueError(\n            f\"total_steps must be between {MIN_TOTAL_STEPS} and {MAX_TOTAL_STEPS}, \"\n            f\"got {total_steps}. Higher values = better quality but slower.\"\n        )\n\n    if silence_duration &lt; 0:\n        raise ValueError(f\"silence_duration must be non-negative, got {silence_duration}\")\n\n    # Validate text characters if verbose\n    is_valid, unsupported = self.model.text_processor.validate_text(text)\n    if not is_valid:\n        raise ValueError(f\"Found {len(unsupported)} unsupported character(s): {unsupported}\")\n\n    # Chunk text for processing\n    text_chunks = chunk_text(text, max_chunk_length)\n\n    if verbose:\n        print(f\"Split into {len(text_chunks)} chunk(s)\")\n        if len(text_chunks) &gt; 1:\n            for i, chunk in enumerate(text_chunks[:3]):  # Show first 3 chunks\n                print(f\"Chunk {i+1}: {chunk[:60]}{'...' if len(chunk) &gt; 60 else ''}\")\n            if len(text_chunks) &gt; 3:\n                print(f\"... and {len(text_chunks) - 3} more chunk(s)\")\n        print(\n            f\"Synthesizing audio... Settings: steps={total_steps}, speed={speed:.2f}x, sample_rate={self.sample_rate}Hz\"\n        )\n\n    # Collect all waveforms and durations in lists to avoid repeated concatenation\n    wav_list = []\n    dur_list = []\n    for i, text_chunk in enumerate(text_chunks):\n        if verbose:\n            print(f\"   [{i+1}/{len(text_chunks)}] Processing chunk... \", end=\"\", flush=True)\n\n        logger.debug(f\"Processing chunk {i+1}/{len(text_chunks)}\")\n        wav, dur_onnx = self.model([text_chunk], voice_style, total_steps, speed)\n\n        if verbose:\n            print(f\"\u2713 ({dur_onnx[0]:.2f}s)\")\n\n        # Validate waveform shape\n        if wav.shape[0] != 1:\n            raise RuntimeError(f\"Expected wav shape (1, samples), got {wav.shape}\")\n\n        wav_list.append(wav)\n        dur_list.append(dur_onnx)\n\n    # Type guard: lists should never be empty after processing\n    assert len(wav_list) &gt; 0 and len(dur_list) &gt; 0, \"No audio generated\"\n\n    # Build list of arrays to concatenate: [wav1, silence, wav2, silence, wav3, ...]\n    silence = np.zeros((1, int(silence_duration * self.sample_rate)), dtype=np.float32)\n    arrays_to_concat = []\n    for i, wav in enumerate(wav_list):\n        arrays_to_concat.append(wav)\n        if i &lt; len(wav_list) - 1:  # Don't add silence after last chunk\n            arrays_to_concat.append(silence)\n\n    # Single concatenation operation\n    wav_cat = np.concatenate(arrays_to_concat, axis=1)\n\n    # Calculate total duration\n    total_audio_dur = sum(dur_list)\n    total_silence_dur = silence_duration * (len(wav_list) - 1)\n    dur_cat = total_audio_dur + total_silence_dur\n\n    if verbose:\n        total_samples = wav_cat.shape[1]\n        print(\"Generation complete!\")\n        print(f\"Total duration: {dur_cat[0]:.2f}s\")\n        print(f\"Total samples: {total_samples:,}\")\n        print(f\"Array shape: {wav_cat.shape}\")\n\n    return wav_cat, dur_cat\n</code></pre>"},{"location":"api/pipeline/#supertonic.pipeline.TTS.save_audio","title":"save_audio","text":"<pre><code>save_audio(wav: ndarray, output_path: str) -&gt; None\n</code></pre> <p>Save synthesized audio to a WAV file.</p> <p>Parameters:</p> Name Type Description Default <code>wav</code> <code>ndarray</code> <p>Audio waveform array from synthesize()</p> required <code>output_path</code> <code>str</code> <p>Path where to save the WAV file</p> required Source code in <code>supertonic/pipeline.py</code> <pre><code>def save_audio(\n    self,\n    wav: np.ndarray,\n    output_path: str,\n) -&gt; None:\n    \"\"\"Save synthesized audio to a WAV file.\n\n    Args:\n        wav: Audio waveform array from synthesize()\n        output_path: Path where to save the WAV file\n    \"\"\"\n    try:\n        import soundfile as sf  # type: ignore[import-untyped]\n    except ImportError as e:\n        logger.error(\"soundfile not installed\")\n        raise ImportError(\n            \"soundfile library is required to save audio. \"\n            \"Install it with: pip install soundfile\"\n        ) from e\n\n    output_path_obj = Path(output_path)\n\n    # Create parent directories if they don't exist\n    output_path_obj.parent.mkdir(parents=True, exist_ok=True)\n\n    # Check write permissions\n    if not os.access(output_path_obj.parent, os.W_OK):\n        raise PermissionError(f\"No write permission for directory: {output_path_obj.parent}\")\n\n    logger.info(f\"Saving audio to {output_path}\")\n    sf.write(str(output_path), wav.squeeze(), self.sample_rate)\n    logger.info(\"Audio saved successfully\")\n</code></pre>"},{"location":"api/utils/","title":"utils","text":""},{"location":"api/utils/#supertonicutils","title":"supertonic.utils","text":""},{"location":"api/utils/#supertonic.utils","title":"supertonic.utils","text":"<p>Utility functions for Supertonic TTS.</p> <p>This module provides various helper functions for text processing, file operations, and timing operations used throughout the Supertonic TTS package.</p> <p>Functions:</p> Name Description <code>sanitize_filename</code> <p>Sanitize filename by replacing non-alphanumeric characters.</p> <code>timer</code> <p>Context manager for timing code execution.</p> <code>format_duration</code> <p>Format duration in seconds to human-readable string.</p> <code>get_audio_duration</code> <p>Calculate audio duration from waveform length.</p> <code>ensure_dir</code> <p>Ensure directory exists, create if necessary.</p> <code>validate_voice_style_format</code> <p>Validate voice style JSON format.</p> <code>chunk_text</code> <p>Split text into chunks by paragraphs and sentences.</p> <p>Attributes:</p> Name Type Description <code>logger</code>"},{"location":"api/utils/#supertonic.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/utils/#supertonic.utils.sanitize_filename","title":"sanitize_filename","text":"<pre><code>sanitize_filename(text: str, max_len: int = 50) -&gt; str\n</code></pre> <p>Sanitize filename by replacing non-alphanumeric characters.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to convert to filename</p> required <code>max_len</code> <code>int</code> <p>Maximum length of filename</p> <code>50</code> <p>Returns:</p> Type Description <code>str</code> <p>Sanitized filename string</p> Source code in <code>supertonic/utils.py</code> <pre><code>def sanitize_filename(text: str, max_len: int = 50) -&gt; str:\n    \"\"\"\n    Sanitize filename by replacing non-alphanumeric characters.\n\n    Args:\n        text: Input text to convert to filename\n        max_len: Maximum length of filename\n\n    Returns:\n        Sanitized filename string\n    \"\"\"\n    prefix = text[:max_len]\n    return re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", prefix)\n</code></pre>"},{"location":"api/utils/#supertonic.utils.timer","title":"timer","text":"<pre><code>timer(name: str, verbose: bool = True)\n</code></pre> <p>Context manager for timing code execution.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the operation being timed</p> required <code>verbose</code> <code>bool</code> <p>Whether to log timing information</p> <code>True</code> Example <pre><code>with timer(\"Processing\"):\n    # Your code here\n    process_data()\n</code></pre> Source code in <code>supertonic/utils.py</code> <pre><code>@contextmanager\ndef timer(name: str, verbose: bool = True):\n    \"\"\"\n    Context manager for timing code execution.\n\n    Args:\n        name: Name of the operation being timed\n        verbose: Whether to log timing information\n\n    Example:\n        ```python\n        with timer(\"Processing\"):\n            # Your code here\n            process_data()\n        ```\n    \"\"\"\n    if verbose:\n        logger.info(f\"{name}...\")\n    start = time.time()\n    yield\n    elapsed = time.time() - start\n    if verbose:\n        logger.info(f\"{name} completed in {elapsed:.2f}s\")\n</code></pre>"},{"location":"api/utils/#supertonic.utils.format_duration","title":"format_duration","text":"<pre><code>format_duration(seconds: float) -&gt; str\n</code></pre> <p>Format duration in seconds to human-readable string.</p> <p>Parameters:</p> Name Type Description Default <code>seconds</code> <code>float</code> <p>Duration in seconds</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted string (e.g., \"1.23s\", \"2m 30s\")</p> Source code in <code>supertonic/utils.py</code> <pre><code>def format_duration(seconds: float) -&gt; str:\n    \"\"\"\n    Format duration in seconds to human-readable string.\n\n    Args:\n        seconds: Duration in seconds\n\n    Returns:\n        Formatted string (e.g., \"1.23s\", \"2m 30s\")\n    \"\"\"\n    if seconds &lt; 60:\n        return f\"{seconds:.2f}s\"\n    elif seconds &lt; 3600:\n        minutes = int(seconds // 60)\n        secs = seconds % 60\n        return f\"{minutes}m {secs:.0f}s\"\n    else:\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        return f\"{hours}h {minutes}m\"\n</code></pre>"},{"location":"api/utils/#supertonic.utils.get_audio_duration","title":"get_audio_duration","text":"<pre><code>get_audio_duration(\n    wav_length: int, sample_rate: int\n) -&gt; float\n</code></pre> <p>Calculate audio duration from waveform length.</p> <p>Parameters:</p> Name Type Description Default <code>wav_length</code> <code>int</code> <p>Number of samples in waveform</p> required <code>sample_rate</code> <code>int</code> <p>Audio sample rate (Hz)</p> required <p>Returns:</p> Type Description <code>float</code> <p>Duration in seconds</p> Source code in <code>supertonic/utils.py</code> <pre><code>def get_audio_duration(wav_length: int, sample_rate: int) -&gt; float:\n    \"\"\"\n    Calculate audio duration from waveform length.\n\n    Args:\n        wav_length: Number of samples in waveform\n        sample_rate: Audio sample rate (Hz)\n\n    Returns:\n        Duration in seconds\n    \"\"\"\n    return wav_length / sample_rate\n</code></pre>"},{"location":"api/utils/#supertonic.utils.ensure_dir","title":"ensure_dir","text":"<pre><code>ensure_dir(path: str) -&gt; str\n</code></pre> <p>Ensure directory exists, create if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Directory path</p> required <p>Returns:</p> Type Description <code>str</code> <p>Absolute path to directory</p> Source code in <code>supertonic/utils.py</code> <pre><code>def ensure_dir(path: str) -&gt; str:\n    \"\"\"\n    Ensure directory exists, create if necessary.\n\n    Args:\n        path: Directory path\n\n    Returns:\n        Absolute path to directory\n    \"\"\"\n    os.makedirs(path, exist_ok=True)\n    return os.path.abspath(path)\n</code></pre>"},{"location":"api/utils/#supertonic.utils.validate_voice_style_format","title":"validate_voice_style_format","text":"<pre><code>validate_voice_style_format(style_data: dict) -&gt; bool\n</code></pre> <p>Validate voice style JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>style_data</code> <code>dict</code> <p>Voice style dictionary</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if valid, False otherwise</p> Source code in <code>supertonic/utils.py</code> <pre><code>def validate_voice_style_format(style_data: dict) -&gt; bool:\n    \"\"\"\n    Validate voice style JSON format.\n\n    Args:\n        style_data: Voice style dictionary\n\n    Returns:\n        True if valid, False otherwise\n    \"\"\"\n    required_keys = [\"style_ttl\", \"style_dp\"]\n    if not all(key in style_data for key in required_keys):\n        return False\n\n    for key in required_keys:\n        if \"dims\" not in style_data[key] or \"data\" not in style_data[key]:\n            return False\n\n    return True\n</code></pre>"},{"location":"api/utils/#supertonic.utils.chunk_text","title":"chunk_text","text":"<pre><code>chunk_text(text: str, max_len: int = 300) -&gt; list[str]\n</code></pre> <p>Split text into chunks by paragraphs and sentences.</p> <p>This function intelligently splits long text into smaller chunks suitable for TTS processing, respecting paragraph and sentence boundaries.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to chunk</p> required <code>max_len</code> <code>int</code> <p>Maximum length of each chunk in characters (default: 300)</p> <code>300</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of text chunks</p> Example <pre><code>text = \"This is a long paragraph. It has multiple sentences. \" * 10\nchunks = chunk_text(text, max_len=100)\nfor chunk in chunks:\n    print(f\"Chunk ({len(chunk)} chars): {chunk[:50]}...\")\n</code></pre> Source code in <code>supertonic/utils.py</code> <pre><code>def chunk_text(text: str, max_len: int = 300) -&gt; list[str]:\n    \"\"\"\n    Split text into chunks by paragraphs and sentences.\n\n    This function intelligently splits long text into smaller chunks suitable\n    for TTS processing, respecting paragraph and sentence boundaries.\n\n    Args:\n        text: Input text to chunk\n        max_len: Maximum length of each chunk in characters (default: 300)\n\n    Returns:\n        List of text chunks\n\n    Example:\n        ```python\n        text = \"This is a long paragraph. It has multiple sentences. \" * 10\n        chunks = chunk_text(text, max_len=100)\n        for chunk in chunks:\n            print(f\"Chunk ({len(chunk)} chars): {chunk[:50]}...\")\n        ```\n    \"\"\"\n    # Validate minimum chunk length\n    if max_len &lt; 10:\n        raise ValueError(\n            f\"max_len must be at least 10, got {max_len}. \"\n            f\"Very small chunks may produce poor quality speech.\"\n        )\n\n    # Split by paragraph (two or more newlines)\n    paragraphs = [p.strip() for p in re.split(r\"\\n\\s*\\n+\", text.strip()) if p.strip()]\n\n    chunks = []\n\n    for paragraph in paragraphs:\n        paragraph = paragraph.strip()\n        if not paragraph:\n            continue\n\n        # Split by sentence boundaries (period, question mark, exclamation mark followed by space)\n        # But exclude common abbreviations like Mr., Mrs., Dr., etc. and single capital letters\n        sentences = re.split(_COMMON_ABBREVIATIONS_PATTERN, paragraph)\n\n        current_chunk = \"\"\n\n        for sentence in sentences:\n            # Skip empty sentences to prevent empty chunks\n            # Strip once and reuse the result\n            sentence_stripped = sentence.strip()\n            if not sentence_stripped:\n                continue\n\n            if len(current_chunk) + len(sentence_stripped) + 1 &lt;= max_len:\n                current_chunk += (\" \" if current_chunk else \"\") + sentence_stripped\n            else:\n                if current_chunk:\n                    chunks.append(current_chunk.strip())\n                current_chunk = sentence_stripped\n\n        # Add final chunk if not empty\n        if current_chunk and current_chunk.strip():\n            chunks.append(current_chunk.strip())\n\n    return chunks\n</code></pre>"},{"location":"argparse/download.inc/","title":"Download.inc","text":""},{"location":"argparse/info.inc/","title":"Info.inc","text":""},{"location":"argparse/list-voices.inc/","title":"List voices.inc","text":""},{"location":"argparse/say.inc/","title":"Say.inc","text":""},{"location":"argparse/say.inc/#text","title":"<code>TEXT</code>","text":"<p>Text to synthesize and play</p>"},{"location":"argparse/say.inc/#-voice","title":"<code>--voice</code>","text":"<p>Voice style (default: M1)</p> <p>Default: <code>M1</code></p>"},{"location":"argparse/say.inc/#-custom-style-path","title":"<code>--custom-style-path</code>","text":"<p>Path to custom voice style JSON file (overrides --voice if provided)</p>"},{"location":"argparse/say.inc/#-steps","title":"<code>--steps</code>","text":"<p>Quality steps (default: 5, higher=better)</p> <p>Default: <code>5</code></p>"},{"location":"argparse/say.inc/#-speed","title":"<code>--speed</code>","text":"<p>Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)</p> <p>Default: <code>1.05</code></p>"},{"location":"argparse/say.inc/#-max-chunk-length","title":"<code>--max-chunk-length</code>","text":"<p>Maximum characters per chunk (default: 300)</p> <p>Default: <code>300</code></p>"},{"location":"argparse/say.inc/#-silence-duration","title":"<code>--silence-duration</code>","text":"<p>Silence between chunks in seconds (default: 0.3)</p> <p>Default: <code>0.3</code></p>"},{"location":"argparse/say.inc/#-v-verbose","title":"<code>-v</code>, <code>--verbose</code>","text":"<p>Enable verbose output with detailed logging</p> <p>Default: <code>False</code></p>"},{"location":"argparse/tts.inc/","title":"Tts.inc","text":""},{"location":"argparse/tts.inc/#text","title":"<code>TEXT</code>","text":"<p>Text to synthesize</p>"},{"location":"argparse/tts.inc/#-o-output","title":"<code>-o</code>, <code>--output</code>","text":"<p>Output WAV file</p>"},{"location":"argparse/tts.inc/#-voice","title":"<code>--voice</code>","text":"<p>Voice style (default: M1)</p> <p>Default: <code>M1</code></p>"},{"location":"argparse/tts.inc/#-custom-style-path","title":"<code>--custom-style-path</code>","text":"<p>Path to custom voice style JSON file (overrides --voice if provided)</p>"},{"location":"argparse/tts.inc/#-steps","title":"<code>--steps</code>","text":"<p>Quality steps (default: 5, higher=better)</p> <p>Default: <code>5</code></p>"},{"location":"argparse/tts.inc/#-speed","title":"<code>--speed</code>","text":"<p>Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)</p> <p>Default: <code>1.05</code></p>"},{"location":"argparse/tts.inc/#-max-chunk-length","title":"<code>--max-chunk-length</code>","text":"<p>Maximum characters per chunk (default: 300)</p> <p>Default: <code>300</code></p>"},{"location":"argparse/tts.inc/#-silence-duration","title":"<code>--silence-duration</code>","text":"<p>Silence between chunks in seconds (default: 0.3)</p> <p>Default: <code>0.3</code></p>"},{"location":"argparse/tts.inc/#-v-verbose","title":"<code>-v</code>, <code>--verbose</code>","text":"<p>Enable verbose output with detailed logging</p> <p>Default: <code>False</code></p>"},{"location":"argparse/version.inc/","title":"Version.inc","text":""},{"location":"cli/","title":"CLI Reference","text":""},{"location":"cli/#supertonic-cli-guide","title":"Supertonic CLI Guide","text":"<pre><code># Quick playback (no file saved)\nsupertonic say TEXT [OPTIONS]\n\n# Text-to-speech (saves to file)\nsupertonic tts TEXT -o OUTPUT.wav [OPTIONS]\n\n# Options:\n#   --voice STYLE             Voice style: M1, M2, F1, F2 (default: M1)\n#   --steps N                 Quality steps: 2-15 typical (default: 5)\n#   --speed RATE              Speed multiplier: 0.7-2.0 (default: 1.05)\n#   --max-chunk-length N      Characters per chunk (default: 300)\n#   --silence-duration SECS   Silence between chunks (default: 0.3)\n#   --verbose, -v             Show detailed progress and text processing\n#   --custom-style-path PATH  Path to custom voice style JSON file (overrides --voice if provided)\n\n# Utilities\nsupertonic list-voices       # List available voices\nsupertonic info             # Show model information\nsupertonic version          # Show version\n</code></pre> <p>The <code>supertonic</code> command-line tool provides easy access to text-to-speech synthesis. You can start by viewing the help message with:</p> <pre><code>supertonic --help\n</code></pre> <p>Available Commands:</p> <pre><code>supertonic {say,tts,list-voices,info,download,version}\n</code></pre>"},{"location":"cli/#say","title":"say","text":"<p>Generate speech from text and play it directly without saving a file.</p> <p>Requires <code>sounddevice</code></p> <p>Install with: <code>pip install supertonic[playback]</code></p> <p>Basic usage:</p> <pre><code>supertonic say 'Hello, welcome to the world!'\n</code></pre> <p>With options:</p> <pre><code># Specify voice style\nsupertonic say 'Hello, welcome to the world!' --voice F1\n\n# Control quality (steps: 2-15 typical)\nsupertonic say 'Hello, welcome to the world!' --steps 10\n\n# Adjust speed (0.7-2.0)\nsupertonic say 'Hello, welcome to the world!' --speed 1.5\n</code></pre> <p>See supertonic say for the full reference of all available arguments.</p>"},{"location":"cli/#tts","title":"tts","text":"<p>Generate speech from text and save to a WAV file.</p> <p>Basic usage:</p> <pre><code>supertonic tts 'Hello, welcome to the world!' -o output.wav\n</code></pre> <p>With options:</p> <pre><code># Specify voice style\nsupertonic tts 'Hello, welcome to the world!' -o output.wav --voice F1\n\n# Control quality (steps: 2-15 typical)\nsupertonic tts 'Hello, welcome to the world!' -o output.wav --steps 10\n\n# Adjust speed (0.7-2.0)\nsupertonic tts 'Hello, welcome to the world!' -o output.wav --speed 1.5\n</code></pre> <p>See supertonic tts for the full reference of all available arguments.</p>"},{"location":"cli/#list-voices","title":"list-voices","text":"<p>List all available voice styles.</p> <pre><code>supertonic list-voices\n</code></pre> <p>Aliases: <code>lv</code></p>"},{"location":"cli/#info","title":"info","text":"<p>Show model information including cache location and available voices.</p> <pre><code>supertonic info\n</code></pre> <p>Aliases: <code>i</code></p>"},{"location":"cli/#download","title":"download","text":"<p>Download model from HuggingFace Hub.</p> <pre><code>supertonic download\n</code></pre> <p>Aliases: <code>d</code></p> <p>This is useful for pre-downloading the model before first use or in Docker/CI environments.</p>"},{"location":"cli/#version","title":"version","text":"<p>Show installed version.</p> <pre><code>supertonic version\n</code></pre> <p>Aliases: <code>v</code></p>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p><code>SUPERTONIC_CACHE_DIR</code></p> <p>Override the default cache directory for model files.</p> <pre><code>export SUPERTONIC_CACHE_DIR=/custom/cache/path\n</code></pre> <p>Default: <code>~/.cache/supertonic</code></p> <p><code>SUPERTONIC_INTRA_OP_THREADS</code></p> <p>Configure ONNX Runtime intra-operator thread count.</p> <pre><code>export SUPERTONIC_INTRA_OP_THREADS=8\n</code></pre> <p>Default: Auto-detected</p> <p><code>SUPERTONIC_INTER_OP_THREADS</code></p> <p>Configure ONNX Runtime inter-operator thread count.</p> <pre><code>export SUPERTONIC_INTER_OP_THREADS=8\n</code></pre> <p>Default: Auto-detected</p>"},{"location":"cli/#more-help","title":"More Help","text":"<p>For detailed options of any subcommand, use:</p> <pre><code>supertonic &lt;subcommand&gt; --help\n</code></pre>"},{"location":"cli/download/","title":"CLI Reference","text":""},{"location":"cli/download/#supertonic-download","title":"supertonic download","text":"<p>Download model from HuggingFace Hub.</p>"},{"location":"cli/download/#usage","title":"Usage","text":"<pre><code>supertonic download\n</code></pre> <p>Aliases: <code>d</code></p>"},{"location":"cli/info/","title":"CLI Reference","text":""},{"location":"cli/info/#supertonic-info","title":"supertonic info","text":"<p>Show model information including cache location and available voices.</p>"},{"location":"cli/info/#usage","title":"Usage","text":"<pre><code>supertonic info\n</code></pre> <p>Aliases: <code>i</code></p>"},{"location":"cli/list-voices/","title":"CLI Reference","text":""},{"location":"cli/list-voices/#supertonic-list-voices","title":"supertonic list-voices","text":"<p>List all available voice styles.</p>"},{"location":"cli/list-voices/#usage","title":"Usage","text":"<pre><code>supertonic list-voices\n</code></pre> <p>Aliases: <code>lv</code></p>"},{"location":"cli/say/","title":"CLI Reference","text":""},{"location":"cli/say/#supertonic-say","title":"supertonic say","text":"<p>Generate speech from text and play it directly without saving a file.</p> <p>Requires <code>sounddevice</code></p> <p>This command requires the <code>sounddevice</code> package for audio playback. Install it with: <code>pip install supertonic[playback]</code> or <code>pip install sounddevice</code></p>"},{"location":"cli/say/#usage","title":"Usage","text":"<pre><code>supertonic say TEXT [OPTIONS]\n</code></pre>"},{"location":"cli/say/#examples","title":"Examples","text":"<pre><code># Basic usage - play speech directly\nsupertonic say 'Hello, welcome to the world!'\n\n# Use a different voice\nsupertonic say 'This is a female voice style.' --voice F1\n\n# Adjust speech speed (faster)\nsupertonic say 'This sentence is spoken at a faster speed than normal.' --speed 1.5\n\n# Higher quality with more steps\nsupertonic say 'This is a high quality output.' --steps 10\n\n# Use custom voice style\nsupertonic say 'This is a custom voice test.' --custom-style-path ./my_voice.json\n\n# Verbose mode to see processing details\nsupertonic say 'Verbose mode shows detailed processing information.' -v\n</code></pre>"},{"location":"cli/say/#arguments","title":"Arguments","text":""},{"location":"cli/say/#text","title":"<code>TEXT</code>","text":"<p>Text to synthesize and play</p>"},{"location":"cli/say/#-voice","title":"<code>--voice</code>","text":"<p>Voice style (default: M1)</p> <p>Default: <code>M1</code></p>"},{"location":"cli/say/#-custom-style-path","title":"<code>--custom-style-path</code>","text":"<p>Path to custom voice style JSON file (overrides --voice if provided)</p>"},{"location":"cli/say/#-steps","title":"<code>--steps</code>","text":"<p>Quality steps (default: 5, higher=better)</p> <p>Default: <code>5</code></p>"},{"location":"cli/say/#-speed","title":"<code>--speed</code>","text":"<p>Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)</p> <p>Default: <code>1.05</code></p>"},{"location":"cli/say/#-max-chunk-length","title":"<code>--max-chunk-length</code>","text":"<p>Maximum characters per chunk (default: 300)</p> <p>Default: <code>300</code></p>"},{"location":"cli/say/#-silence-duration","title":"<code>--silence-duration</code>","text":"<p>Silence between chunks in seconds (default: 0.3)</p> <p>Default: <code>0.3</code></p>"},{"location":"cli/say/#-v-verbose","title":"<code>-v</code>, <code>--verbose</code>","text":"<p>Enable verbose output with detailed logging</p> <p>Default: <code>False</code></p>"},{"location":"cli/tts/","title":"CLI Reference","text":""},{"location":"cli/tts/#supertonic-tts","title":"supertonic tts","text":"<p>Generate speech from text and save to a WAV file.</p>"},{"location":"cli/tts/#usage","title":"Usage","text":"<pre><code>supertonic tts TEXT -o OUTPUT.wav [OPTIONS]\n</code></pre> <p>Aliases: <code>t</code></p>"},{"location":"cli/tts/#arguments","title":"Arguments","text":""},{"location":"cli/tts/#text","title":"<code>TEXT</code>","text":"<p>Text to synthesize</p>"},{"location":"cli/tts/#-o-output","title":"<code>-o</code>, <code>--output</code>","text":"<p>Output WAV file</p>"},{"location":"cli/tts/#-voice","title":"<code>--voice</code>","text":"<p>Voice style (default: M1)</p> <p>Default: <code>M1</code></p>"},{"location":"cli/tts/#-custom-style-path","title":"<code>--custom-style-path</code>","text":"<p>Path to custom voice style JSON file (overrides --voice if provided)</p>"},{"location":"cli/tts/#-steps","title":"<code>--steps</code>","text":"<p>Quality steps (default: 5, higher=better)</p> <p>Default: <code>5</code></p>"},{"location":"cli/tts/#-speed","title":"<code>--speed</code>","text":"<p>Speech speed (0.7-2.0, default: 1.05, 2.0=2x faster)</p> <p>Default: <code>1.05</code></p>"},{"location":"cli/tts/#-max-chunk-length","title":"<code>--max-chunk-length</code>","text":"<p>Maximum characters per chunk (default: 300)</p> <p>Default: <code>300</code></p>"},{"location":"cli/tts/#-silence-duration","title":"<code>--silence-duration</code>","text":"<p>Silence between chunks in seconds (default: 0.3)</p> <p>Default: <code>0.3</code></p>"},{"location":"cli/tts/#-v-verbose","title":"<code>-v</code>, <code>--verbose</code>","text":"<p>Enable verbose output with detailed logging</p> <p>Default: <code>False</code></p>"},{"location":"cli/version/","title":"CLI Reference","text":""},{"location":"cli/version/#supertonic-version","title":"supertonic version","text":"<p>Show installed version.</p>"},{"location":"cli/version/#usage","title":"Usage","text":"<pre><code>supertonic version\n</code></pre> <p>Aliases: <code>v</code></p>"}]}